<!DOCTYPE html>
<html>
<head>
  <title>NSCH Machine Learning Project</title>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0; 
    }
    .tab-bar {
      background-color: #333;
      overflow: hidden;
    }
    .tab-bar button {
      background-color: inherit;
      border: none;
      color: white;
      padding: 14px 16px;
      cursor: pointer;
      float: left;
      font-size: 16px;
    }
    .tab-bar button:hover {
      background-color: #575757;
    }
    .tab-bar button.active {
      background-color: #4CAF50;
    }
    .tab-content {
      display: none;
      padding: 20px;
    }
    .tab-content.active {
      display: block;
    }

    .top-images {
      display: flex;
      justify-content: center;   /* center horizontally */
      align-items: center;       /* align vertically if needed */
      gap: 10px; /* Optional: adds space between images */
      flex-wrap: wrap; /* Optional: allows wrapping on smaller screens */
    }
    
    .top-images img {
      max-width: 100%; /* Makes images responsive */
      height: auto;
      width: 300px; /* Adjust size as needed */
    }

    
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
      font-size: 16px;
    }

    table, th, td {
      border: 1px solid #ccc;
    }

    th, td {
      padding: 10px;
      vertical-align: top;
    }

    caption {
      caption-side: top;
      margin-bottom: 8px;
    }

    /* Reference list styling */
    .ref-list {
      margin-left: 1.2em;       /* indentation */
      line-height: 1.4;
    }

    .ref-list li {
      margin-bottom: 12px;      /* spacing between items */
    }

    .ref-list a {
      color: #0645AD;           /* typical link blue */
      text-decoration: underline;
    }

    .ref-list a:hover {
      color: #0B0080;           /* darker hover color */
    }

    .qa-list li {
      margin-bottom: 20px;
    }
    .question {
      font-weight: bold;
      margin-bottom: 5px;
    }
    .answer {
      margin-left: 10px;
      color: #444;
    }
    
  </style>
</head>
<body>
  
  <!-- Navigation Bar with Buttons -->
  <div class="tab-bar">
    <button class="tab-link active" onclick="openTab(event, 'Introduction')">Introduction</button>
    <button class="tab-link" onclick="openTab(event, 'DataPrep_EDA')">DataPrep_EDA</button>
    <button class="tab-link" onclick="openTab(event, 'Clustering')">Clustering</button>
    <button class="tab-link" onclick="openTab(event, 'PCA (Principle Component Analysis)')">PCA (Principle Component Analysis)</button>
    <button class="tab-link" onclick="openTab(event, 'NaiveBayes')">NaiveBayes</button>
    <button class="tab-link" onclick="openTab(event, 'DecTrees')">DecTrees</button>
    <button class="tab-link" onclick="openTab(event, 'Boosting')">Boosting</button>
    <button class="tab-link" onclick="openTab(event, 'Results')">Results</button>
    <button class="tab-link" onclick="openTab(event, 'ProjectChallenges')">ProjectChallenges</button>
    <button class="tab-link" onclick="openTab(event, 'Conclusions')">Conclusions</button>
    <button class="tab-link" onclick="openTab(event, 'References')">References</button>
    <button class="tab-link" onclick="openTab(event, 'About_Me')">About_Me</button>
  </div>

  <!-- Content Sections -->
  <div id="Introduction" class="tab-content active">
    
    <h1>Exploring Child Health with Data from the National Survey of Children's Health (NSCH) and America's Health Rankings (AHR)</h1>
    
    <img src="Website_Pic2.JPG" alt="Introduction image">
    
    <h3>Background</h3>
    
    <p>
      In 2002, Nelson Mandela spoke at the AIDS Vaccine Conference in South Africa, delivering a powerful speech about the responsibility of all 
      people to support the health and well-being of children. He said:
      
    <blockquote style="border-left: 4px solid #ccc; margin: 1em 0; padding-left: 1em; color: #333;">
      Giving children a healthy start in life, no matter where they are born or the circumstances of their birth,<br>
      is the moral obligation of every one of us. It is heartbreaking to think that three million children die each<br>
      year from diseases that we can prevent.<br><br>
      These are three million needless deaths every year. These are children that would have grown up to support<br>
      their families, their communities and their nations.<br><br>
      They would have been productive members of societies that are still developing and need their children to be<br>
      healthy and strong. By preventing these deaths, we would not only save the lives of children but we would also<br>
      help strengthen communities and contribute to the development of strong and prosperous nations.
    </blockquote> 

    </p>  
    
    <p>
      Research supports Mandela’s assertions linking child health and community prosperity. According to a recent consensus study 
      report from the National Academies of Sciences, Engineering, and Medicine - Board on Children, Youth, and Families, adult health begins in 
      childhood, and improving the health of children has enormous societal gains (Chang, 2024). The report advocates for all children to receive 
      a healthy start in life. In the future, children will become caregivers of their own parents and children. Additionally, improving children's 
      health stems chronic disease progression. Many conditions experienced by adults, such as diabetes and obesity, begin in childhood. As such, 
      prevention efforts should start early in life. The authors also discuss the recent advances in health diagnostics and treatment, including 
      genomics and predictive personalized medicine, which lead to early detection and management of inherited and chronic conditions.  
    </p>

    <p>
      Nations experience greater productivity and economic gains when children are healthy (Chang, 2024). According to UNICEF (UNICEF, 2005), "child health and wellbeing 
      support the nation’s tax base, workforce, economic prosperity, and sustain a high standard of living." There are reduced costs of caring for 
      sick children. For example, when children are ill, parents miss work, play and rest, affecting their overall well-being and productivity. 
      Healthcare may also be expensive, resulting in an additional financial burden on the family.       
    </p> 

    <p>
      From early diagnosis to personalized care and support, machine learning can help in all aspects of child health. These methods allow researchers to identify policies 
      and practices that result in the best outcomes with the most impactful use of limited funds.<br>
    </p>
    
    <br>
      <b>Illustration: Machine Learning Contributes to All Aspects of Child Health</b><br>
      <img src="images/ML_ChildHealth.png" alt="Intro2" style="width: 1200px; height: auto;"><br><br>
     
     
    
    <h3>Research Purpose and Aims</h3>
    <p>
      The purpose of this investigation is to explore characteristics of healthy children and aims to draw insights from the 2023
      <a href="https://www.childhealthdata.org/learn-about-the-nsch" target="_blank">National Survey of Children's Health (NSCH)</a> 
      and 
      <a href="https://www.childhealthdata.org/learn-about-the-nsch" target="_blank">America's Health Rankings (AHR).</a> 
    </p>
    
    <p>
      NSCH is a survey developed and administered annually by the U.S. Census Bureau with funding from the
      <a href="https://www.hrsa.gov" target="_blank">Health Resources and Services Administration (HRSA)</a>,
      <a href="https://mchb.hrsa.gov" target="_blank">Maternal and Child Health Bureau (MCHB)</a>.
      This household survey began in 2003 and collects data on the physical and mental health of children 0–17 years old. All 50 states
      and the District of Columbia participate.  
    </p> 

    <p>
      The 2023 NSCH includes the following topics:
      <ul> 
        <li>Demographics for the children and families</li>
        <li>Children’s physical and mental health status</li>
        <li>Health insurance status, adequacy, and type of coverage</li>
        <li>Access to and use of health care services</li>
        <li>Early childhood characteristics (0-5 years)</li>
        <li>Middle childhood and adolescent characteristics (6-17 years)</li>
        <li>Family health and activities</li>
        <li>Parental perceptions of neighborhood and community characteristics</li> 
      </ul>
    </p>
    
    <p> 
      Since 1990, the AHR has taken stock of the health and well-being of Americans each year by examining 280 measures of health from 80 distinct data sources. 
      Topics include:
      <ul> 
        <li>measures of care, such as access to care, preventative clinical care, quality of care,</li>
        <li>measures of health, such as mortality, nutrition and physical activity, physical health, sexual health, sleep, smoking and tobacco use, behavioral health, </li>  
        <li>environmental factors, including air and water quality and climate and health,</li> 
        <li>community characteristics, such as safety, economic resources, housing and transit,</li>
        <li>family characteristics, including demographics, education, </li>
        <li> social support and engagement. </li>
      </ul>
    </p>

    <p>
      NSCH and AHR data help communities and families make informed decisions to support the health and well-being of the children and youth in their
      care. Community-level data are available for participating areas, allowing them to compare their location to neighboring communities, other 
      states and the nation. Local public health agencies, day-care centers and schools can use their results to evaluate their systems and 
      processes, gaining insights into where improvements can be made. These data also promote inter-agency cooperation for reform and lasting 
      change. For example, data sharing can encourage greater openness among schools, medical and mental-health providers, police and the courts. 
      Data from the NSCH and AHR are used for a variety of purposes. As such, a large body of reports and peer-reviewed publications are available. 
      NSCH publications include exploring aspects of overall child health, school-readiness, mental health and children with special needs. 
      A full list of NSCH publications authored by MCHB staff is available through the  
      <a href="https://mchb.hrsa.gov/data-research/national-survey-childrens-health/publications-presentations" target="_blank">NSCH Publications Page</a>. 
      AHR reports are available on their 
      <a href="https://www.americashealthrankings.org/learn/reports" target="_blank">reports page</a>. 
    </p>
        
    <p>
      This project explores the NSCH 2023 and AHR databases with machine learning techniques including K-means clustering and hierarchical clustering, principle component analysis, 
      Naïve Bayes, decision trees, random forest, and XGBoost. Analyses are limited to individual and state-level comparisons. Identifiers at the local level, such as city or zip code, 
      are not available on the NSCH public database.
    </p>  

    <p>
      This research began with the 10 questions listed below under <b>Q&A</b>, which were initially investigated through exploratory data analysis (EDA). State-level comparisons include the 50 states 
      and District of Columbia (N=51). State-wide estimates of NSCH are generated by combining the child’s weighted counts for each response over the weighted total possible responses 
      to obtain state-level weighted percentages (N=51). Individual-level comparisons for the NSCH are weighted with the sampling and response weights and include all respondents 
      with non-missing values (unweight N=54,159, weighted N=~14 million).
    </p>
    
    <div class="top-images">
      <img src="images/Child_immunized.png" alt="question immune">
      <img src="images/Sleepy_Teen.png" alt="question sleep">
      <img src="images/Preventative_Care_Visit.png" alt="question pcare">
    </div>
    
    <p>
        EDA identified interesting patterns in the data. After this initial pass through the data, the analysis honed in on questions 1, 6, 9, and 10 from the <b>Q&A</b> below, specifically:<br>
        <ul>
          <li>Question 1: What state-wide factors predict state-wide immunization coverage by 24-months?</li>
          <li>Question 6: What state-wide features predict state-wide insurance coverage?</li>
          <li>Question 9: Among teenagers, what features predict inadequate sleep?  </li>
          <li>Question 10: What factors contribute to children not accessing preventive care?</li>
        </ul>  

        We employed K-means clustering and hierarchical clustering methods to explore Question 1, focusing on only two predictors. Further exploration expanded the predictors to 10 state-wide features, 
        specifically: 1) receiving preventative care, 2) children in excellent/very good health, 3) having a place to receive health care, 4) insurance coverage, 5) adults completing high school,
        6) population < 18 years old, 7) above the federal poverty line, 8) primary care providers per 100,000, 9) public health spending per capita, and 10) supportive engagement. For this 
        question, we implemented principal component analysis for feature reduction to find patterns in the state-characteristics leading to immunization coverage. With a similar list of state-level 
        features, we examined Question 6 with a decision tree model.<br>
        <br>
        Questions 9 and 10 evaluate data at the individual child-level. We analyzed Question 9 using Bernoulli Naïve Bayes with dichotomized variables for: screen time usage, age, housing instability, 
        family food and cash assistance, adequate and continuous insurance, health status, preventative care visits, and place to get health care. For Question 10, we assessed the performance of 
        decision tree, random forest and XGBoost classification.<br>
              
    </p>  

<h3>Q&A</h3>

<ol class="qa-list">
  <li>
    <p class="question">What state-wide factors predict state-wide immunization coverage by 24-months?</p>
    <p class="answer">Preventative care and insurance coverage are good predictors of immunization coverage. States that have similar rates of insurance and preventative care coverage cluster together. 
      Theses results identify that a gap in coverage for insurance and preventative care corresponds to a gap in childhood immunization rates. This interdependency suggests that improving one of these measures 
      may positively influence the others. PCA analysis supported these findings showing that states with higher populations <18, fewer primary care providers, less preventative care and reduced insurance coverage 
      may require additional support to increase immunization coverage.</p>
  </li>

  <li>
    <p class="question">What impact does the percentage of children who received all recommended vaccines by 24 months have on children receiving preventative care check-ups at the state-level?</p>
    <p class="answer">Median vaccine coverage was 67.7% across the states. If we considered < 67.5% as low coverage and 67.5% or greater as medium to high coverage, we see that the percentage of children receiving at 
      least one preventative care visit is slightly higher in the medium or high group. Specifically, in the low immunization group, a median of 79.4% of children and for the medium or high group, a median of 80.9% of 
      children received a preventative care visit. This suggests that preventative care may play a role in childhood immunization coverage.</p>
  </li>

  <li>
    <p class="question">How does state-level public health funding per person influence number of active primary care providers per 100,000 population at the state-level?</p>
    <p class="answer">On average, states spend between $100-200 per capita on public health (median(P25, P75) = $123 (96.0, 156.5)). As per capita public health spending increases, the number of active primary care providers 
      per 100,000 people also increased.</p>
  </li>

  <li>
    <p class="question">How does the number of active primary care providers per 100,000 population at the state-level relate to children having a place to receive care regularly?</p>
    <p class="answer">As the number of active primary care providers per 100,000 population increases, the percentage of children who have a regular place to receive care also increases. </p>
  </li>

  <li>
    <p class="question">How does at least one preventative care visit influence overall child health at the individual-level?</p>
    <p class="answer">Health status does not differ by whether a child had a preventative care visit. The proportion of children in each of the five health status groups appears similar for those with and without 
      preventative care.</p>
  </li>

  <li>
    <p class="question">What state-wide features predict state-wide insurance coverage?</p>
    <p class="answer">Per capita spending on public health of at least $147 per person delineated the data fairly well into states with and without good insurance coverage. This has important implications for states 
      hoping to bolster insurance coverage for their residents. Since the median public health spending is $123, on average states would only need to increase their spending by approximately $24 per person in order 
      to reach this threshold. Such an investment could provide residents with greater access to health coverage. </p>
  </li>

  <li>
    <p class="question">How does a family's poverty level impact overall child health?</p>
    <p class="answer">As overall health status decreases, the proportion of children at the highest income group (i.e. 400% or more of the poverty level) also decreases. The relationship between health status and poverty 
      is also evaluated for those below the federal poverty level and shows that as health worsens more children are in families below the poverty level.</p>
  </li>

  <li>
    <p class="question">What is the relationship between benefits from the Women, Infants, and Children (WIC) Program and overall child health?</p>
    <p class="answer">The most vulnerable health groups are those children in the "good", "fair" and "poor" categories. We see that families that have support from WIC tend to be in the "good" and "fair" categories and 
      less so in the "poor" health category.</p>
  </li>

  <li>
    <p class="question">Among teenagers, what features predict inadequate sleep?</p>
    <p class="answer">Limiting screen time appears to play a role for adequate hours of sleep for teenagers. Once the average hours of screen time exceed 1 hour per day, the weighted proportion of teens experiencing 
      inadequate sleep nearly doubles from 17% for 1 hour to 33% for 4 or more hours. Other influential features for inadequate sleep included: older teens, housing instability and children in poorer health. Helping 
      these groups obtain enough sleep could improve their overall physical and mental health.</p>
  </li>

  <li>
    <p class="question">What factors contribute to children not accessing preventive care?</p>
    <p class="answer">The percentage of children receiving at least one preventative care visit ranged from 69.8% to 89.3%. Not having a usual place to receive health care is the most predictive feature of 
      not receiving preventative care. Other features, such as poverty, moving, lower education, older children and living outside of the Northeast, were also important features. For example, states reported over 10% 
      of households living below the federal poverty level (median(P25, P75) = 12.2(11.05,13.65)). As the percentage of households below the federal poverty level increases (i.e. more people living in poverty), 
      the percentage of children receiving preventative care decreases. Additionally, children experiencing housing instability or living three or more places in the last year received a preventative care visit 69% of 
      the time. Conversely, 80% of children who did not move more than once experienced a preventative care visit. These relationships suggests that targeting those who are most likely to miss visits with public health 
      messaging and helping people find a regular place for care are viable interventions in increasing preventative care coverage.</p>
  </li>
</ol>    
           
    <h3>References</h3>
    <p>
      <ul> 
        <li>Mandela, N. Address by Nelson Mandela at Vaccine Conference. South Africa 2002. 
          Available from: http://www.mandela.gov.za/mandela_speeches/2002/0204_vaccine.htm </li>
        <li>National Academies of Sciences, Engineering, and Medicine; Health and Medicine Division; Board on Health Care Services; Division of Behavioral and 
          Social Sciences and Education; Board on Children, Youth, and Families; Committee on Improving the Health and Wellbeing of Children and Youth through 
          Health Care System Transformation; Perrin JM, Cheng TL, editors. Launching Lifelong Health by Improving Health Care for Children, Youth, and Families. 
          Washington (DC): National Academies Press (US); 2024 Dec 30. 1, Child Health and Health Care: Uniqueness, Societal Importance, and Vision for the Future. 
          Available from: https://www.ncbi.nlm.nih.gov/books/NBK610738/</li>
        <li>United Nations International Children’s Emergency Fund (UNICEF). Report card no. 6: Child poverty in rich countries 2005. UNICEF Innocenti Research Centre; 
          2005. Available from: https://www​.unicef-irc​.org/publications/pdf/repcard6e.pdf</li>
      </ul>
    

  </div>

  <div id="DataPrep_EDA" class="tab-content">

    <h1>Data Preparation & Exploratory Data Analysis</h1>
    
    <img src="Website_Pic3.jpg" alt="EDA image." width="1200">

    <h3>Data Preparation</h3>
    <p>
      <br>
      The NSCH 2023 data are not available directly through an API, as users must agree to follow 
      the NSCH data use requirements. Instead, SAS, Stata, or CSV data files with corresponding codebooks can be downloaded from the 
      <a href="https://www.childhealthdata.org/help/dataset" target="_blank">Data Resource Center</a> 
      and the 
      <a href="https://www.census.gov/programs-surveys/nsch/data/datasets.html" target="_blank">US Census Bureau</a>. Due to these 
      requirements, the data are not stored directly on the GitHub page, as each user must agree to these conditions.
      <br>
      Once the NSCH 2023 CSV file was downloaded, the data were read into Python using the program
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/1a_NSCH_family_data.ipynb" target="_blank" rel="noopener noreferrer">
        1a_NSCH_family.
      </a>
       Identifiers and features of interest were kept. The NSCH data include FIPS codes for the states. New variables for the state long and short names were added. Missing codes of 95 and 99 
      were replaced with NAN. Records that were missing data for important analysis variables were removed, as the number missing relative to 
      the total is small, specifically:      
      <ul> 
        <li>overall health of the child (missing 131),</li>
        <li>preventative care (missing 457), </li>
        <li>regular place to receive care when the child when sick (missing 219),</li>
        <li>insurance satus (missing 348),</li>
        <li>poverty level not missing, as they used imputation</li>
      </ul>
      <br>
      Other variables that are missing more often are family WIC status (missing 1272), screen time (missing 749), and number of places lived 
      in the last year (missing 1420). For analyses which include these variables, we will limit the analysis to non-missing responses, as 
      missing values are across all states and appear to be missing at random. Lastly, the program outputs a csv file (NSCH_fam.csv with 
      N=54,159 children).
      <br>
      Next, the child-level data (NSCH_fam.csv) are rolled-up to the state-level by calculating weighted proportions of the children with a 
      given response using the Python program
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/1b_NSCH_state_data.ipynb" target="_blank" rel="noopener noreferrer">
        1b_NSCH_state_data.  
      </a>
      A csv file with the state-level weighted proportions is output (NSCH_state.csv with 51 records (each of the 50 states and Washington DC)).
      
      <br>    
      The AHR data are available through the 
      <a href="https://developers.americashealthrankings.org/" target="_blank">AHR API</a>, which requires that users register and obtain an API 
      key. Data use is intended for non-commercial, educational, scientific, or charitable use. Additionally, attribution of source (AHR and any
      underlying data sources) is required in any output.<br>
      <br>
      The API was called using Python following the code  
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/1c_AHR_API_and_state_data.ipynb" target="_blank" rel="noopener noreferrer">
        1c_AHR_API_and_state_data.
      </a>  
      A csv file of the data was output (AHR_state.csv with 51 records).
      <br>
      Finally, the NSCH and AHR state-level data were merged together and the combined data was output (NSCH_AHR_state. with 51 records) using the python program 
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/1d_NSCH_AHR_combined_state_data.ipynb" target="_blank" rel="noopener noreferrer">
        1d_NSCH_AHR_combined_state_data.
      </a>
      This datafile includes analysis variables, which are used in the data exploration and analysis.
      
    </p>
    <br>
    <h3>Exploratory Data Analysis (EDA)</h3>
   
    <p>
      This research explored 10 questions in Python using the program: 
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/2_NSCH_AHR_Visualizations.ipynb" target="_blank" rel="noopener noreferrer">
        2_NSCH_AHR_Visualizations.
      </a>
      
      Results of the EDA for each question are provided below. As a reminder, state-level comparisons 
      included the 50 states and District of Columbia (N=51). For state-level comparisons, the NSCH was weighted using the sampling and response rate for the child and 
      rolled up to the state level. Individual-level comparisons for the NSCH are weighted with the sampling and response weights and include all respondents with non-missing
      values (N=54,159). 
    </p>
    <p>
      <b>Question 1: What state-wide factors predict state-wide immunization coverage (<b>AHR, 18114:vaccination, low versus medium or high coverage</b>) by 24-months?</b>
      <br><br>  
         
    <b>Figure 1</b><br>
    <img src="images/Q2_good_immun_pairwise_scatter.png" alt="Q2 pairwise scatter" width="1200"><br><br>
      
    </p>
    <br>
    <p>    
      <b>Question 2: What impact does the percentage of children who received by age 24 months all recommended vaccines (<b>AHR, 18114:vaccination, low versus medium or high coverage</b>) 
          have on children receiving preventative care check-ups (<b>NSCH, state-level, C1/C2, 1 or more visits versus no visits, PrevMed_23</b>)?</b>
      <br><br>
      Median vaccine coverage was 67.7% across the states. If we considered < 67.5% as low coverage and 67.5% or greater as medium to high coverage, we see that the percentage 
      of children receiving at least one preventative care visit is slightly higher in the medium or high group. Specifically, in the low immunization group, a median 
      of 79.4% of children and for the medium or high group, a median of 80.9% of children received a preventative care visit. This suggests that preventative care may 
      play a role in childhood immunization coverage.<br>
      <br>
      <b>Figure 2</b><br>
      <img src="images/Q2_preventative_care_good_immun_cat_box.png" alt="Q2 Immunization Coverage Boxplot" width="1200"><br><br>
    </p>
    <br>
    <p>        
      <b>Question 3: How does public health funding per person (<b>AHR, 3837:public health funding</b>) influence number of active primary care providers per 100,000 population (<b>AHR, 
          17673:primary care provider</b>)?</b>
      <br><br>
      On average, states spend between $100-200 per capita on public health (median(P25, P75) = $123 (96.0, 156.5)). As shown in Figure 3, as per capita public health 
      spending increases, the number of active primary care providers per 100,000 people also increased.<br>
      <br>
      <b>Figure 3</b><br>
      <img src="images/Q3_providers_public_health_reg_LT400.png" alt="Q3 Providers Public Health" width="1200"><br><br>
      Of note, Washington DC is excluded from Figure 4. DC has 553.6 active providers per 100,000, and public health spending per capita in DC is $1,084.
    </p>
    <br>
    <p>
      <b>Question 4: How does the number of active primary care providers per 100,000 population (<b>AHR, 17673:primary care provider</b>) 
        relate to a child having a place to receive care regularly (<b>NSCH, state-level, C8, place usually take child when sick, K4Q01</b>)? </b>   
      <br><br>
      As the number of active primary care providers per 100,000 population increases, the percentage of children who have a regular place to 
      receive care also increases (Figure 4).<br>
      <br>
      <b>Figure 4</b><br>
      <img src="images/Q4_place_for_care_providers_reg_LT450.png" alt="Q4 Place For Care Providers" width="1200"><br><br>
      Of note, Washington DC is excluded from Figure 4. DC has 553.6 active providers per 100,000, and the percent of children in DC who have a place 
      to receive care regularly is 77.6%.
    </p>
    <br>
    <p>  
      <b>Question 5: How does at least one preventative care visit (<b>NSCH, individual-level, C1/C2, 1 or more visits versus no visits, PrevMed_23</b>) influence overall child health 
          (<b>NSCH, individual-level, A1, excellent/very good/good/fair/poor, K2Q01</b>)?</b>
      <br><br>
      Health status does not differ by whether a child had a preventative care visit. The proportion of children in each of the five health status groups appears 
      similar for those with and without preventative care (Figure 5).<br>
      <br>
      <b>Figure 5</b><br>
      <img src="images/Q5_PrevMed_K2Q01_bar.png" alt="Q5 Preventive Medical Visits Bar" width="1200"><br><br> 
    </p>
    <br>
    <p>   
      <b>Question 6: What features predict insurance coverage (<b>NSCH, individual-level, E2/E3, insurance status, smAdeqIns_23 rolled up</b> and 
      <b>AHR, 16125:Uninsured</b>)?</b>
      <br><br>
      We first evaluated the child level data before exploring the state-level data. As the child's health status worsens from 'Excellent' to 'Poor', we see a trend with adequate insurance coverage decreasing. 
      As shown in Figure 6, among those with excellent health, 69% have adequate insurance. This drops to 45% having adequate insurance among those with poor health.<br>
      <br>
      <b>Figure 6</b><br>
      <img src="images/Q6_K2Q01_smAdeqIns_heat.png" alt="Q6 Adequate Insurance Heatmap" width="1200"><br><br>
    </p>
    <br>
    <p>     
      <b>Question 7: How does family's poverty level (<b>NSCH, individual-level, K3, income, povlev4_23	(Income level based on family poverty level status, imputed) </b>) impact overall 
          child health (<b>NSCH, individual-level, A1, excellent/very good/good/fair/poor, nomChHlthSt_23</b>)?</b>
      <br><br>
      As overall health status decreases, the proportion of children at the highest income group (i.e. 400% or more of the poverty level) also decreases (Figure 7a). 
      The relationship between health status and poverty is also evaluated for those below the federal poverty level in Figure 7b and shows that as health worsens more children
      are in families below the poverty level.<br>
      <br>
      <b>Figure 7a</b><br>
      <img src="images/Q7_K2Q01_povlev4_bar.png" alt="Q7 Poverty Level Barplot" width="1200"><br><br>
      <br>
      <br>
      <b>Figure 7b</b><br>
      <img src="images/Q7_K2Q01_povlev4_line.png" alt="Q7 Poverty Level Lineplot" width="1200"><br><br>
    </p>
    <br>
    <p>   
      <b>Question 8: What is the relationship between benefits from the Women, Infants, and Children (WIC) Program (<b>NSCH, individual-level, I7, Yes/No, WIC_23</b>)) and overall child health 
          (<b>NSCH, individual-level, A1, excellent/very good/good/fair/poor, nomChHlthSt_23</b>)? </b>
      <br><br>
      The most vulnerable health groups are those children in the "good", "fair" and "poor" categories. We see that families that have support from WIC tend to be in the "good" and "fair" 
      categories and less so in the "poor" health category. <br>
      <br>
      <b>Figure 8</b><br>
      <img src="images/Q8_K2Q01_WIC_line.png" alt="Q8 WIC Lineplot" width="1200"><br><br>
    </p>
    <br>
    <p>       
      <b>Question 9: Among teenagers, what features predict inadequate sleep (less than the average recommended number of hours for age) (<b>NSCH, individual-level, H5, hours, HrsSleep_23
          (Child slept recommended age-appropriate hours during an average day/on most weeknights, age 4 months – 17)</b>)? </b>
      <br><br>
      Limiting screen time appears to play a role for adequate hours of sleep for teenagers. Once the average hours of screen time exceed 1 hour per day, the weighted proportion of teens 
      experiencing inadequate sleep nearly doubles from 17% for 1 hour to 33% for 4 or more hours. <br>
      <br>
      <b>Figure 9</b><br>
      <img src="images/Q9_ScreenTime_HrsSleepNo_Line.png" alt="Q9 ScreenTime & HrsSleep Lineplot" width="1200"><br><br>
    </p>
    <br>
    <p>  
      <b>Question 10: What factors contribute to children not accessing preventive care check-ups (<b>NSCH, individual-level, C1/C2, 1 or more visits versus no visits, PrevMed_23</b>)?</b>
      <br><br>
      Children experiencing housing instability or living three or more places in the last year received a preventative care visit 69% of the time. Conversely, 80% of children who did not move more 
      than once experienced a preventative care visit.<br>
      <br>
      <b>Table 1</b><br>
      <img src="images/Q10_PrevMed_PlacesLived_Tab.png" alt="Q10 Preventive Medical Visits by Places Lived" width="1200"><br><br>

      On average, states reported over 10% of households living below the federal poverty level (median(P25, P75) = 12.2(11.05,13.65)). The percentage of children 
      receiving at least one preventative care visit ranged from 69.8% to 89.3%. As the percentage of households below the federal poverty 
      level increases (i.e. more people living in poverty), the percentage of children receiving preventative care decreases.<br>  
    </p>
     
  </div>

  <div id="Clustering" class="tab-content">
    
    <h1>Clustering</h1>

    
    <div class="top-images">
      <img src="Website_Pic10.jpg" alt="Cluster image 3">
      <img src="Website_Pic17.jpg" alt="Cluster image 2">
      <img src="Website_Pic4.jpg" alt="Cluster image 1">
    </div>
    
    <p>
      This section includes the results and visualizations from employing K-means and hierarchical clustering.
    </p>
    <br>
    <h3>Overview</h3>
   
    <p> 
      Clustering, a type of unsupervised and non-parametric learning, can be carried out primarily through two different approaches. The first utilizes partitional methods in which 
      observations are organized together based on similar characteristics. K-Means clustering is one of these approaches and groups observations based on the their Euclidean distance from the 
      cluster centroids. Points are assigned the cluster closest to the given observation. After the first iteration, the process is repeated, recomputing the centroids and the clusters for 
      each point. This continues until the cluster assignments reach static equilibrium and the clusters remain the same. <br>
      
      <br>
      <b>Illustration of K Means Clustering (Source: Davis, 2024)</b><br>
      <img src="images/K_Means_Davis_Towards_Data_Science.gif" alt="K_Means_Davis_TDS" style="width: 1200px; height: auto;"><br><br>
            
      K-Means can be sensitive to the initial pick of k as well as outliers. We can address the challenges of picking k by implementing the elbow method, gap statistic and/or silhouette method. 
      Although there are more sophisticated clustering methods that do not have these issues, K-Means provides a great first pass for initial data mining.<br> 
      <br>
      The second approach is hierarchical clustering, which groups observations together either by splitting observations into smaller and smaller clusters (i.e. divisive or top-down 
      hierarchical clustering) or joining observations together from the bottom-up (i.e. agglomerative clustering (AGNES)). AGNES begins with each observation as its own cluster. Points are
      merged together with other observations that are the most similar to the point, where similarity is based on distance. An advantage of hierarchical clustering is that the method does 
      not require specifying the number of clusters in advance. Additionally, as with K-Means, distance can assessed using Euclidean distance; however, other distances, such as Manhattan, 
      maximum and Ward can also be used.<br> 

      <br>
      <b>Illustration of Hierarchical Clustering (Source: Davis, 2024)</b><br>
      <img src="images/Hierarchical_Clustering_Davis_Towards_Data_Science.webp" alt="HC_Davis_TDS" style="width: 1200px; height: auto;"><br><br>        
      
      <br>
      For this analysis, both K-Means and hierarchical clustering were used to uncover patterns in the data. The primary question of interest addresses Question1, which explores features 
      related to good vaccination coverage for children by age two. The outcome of interest for this analysis is good vaccination coverage where < 67.5% coverage of the state 
      population is low coverage and 67.5% or greater is medium to high coverage. <br>
      <br>
      <b>Figure 10</b><br>
      <img src="images/Q2_insured_pcare_good_immun_scatter.png" alt="Q2 Good Immunization Scatterplot" style="width: 1200px; height: auto;"><br><br>

      As shown in Figure 10, there is a positive correlation between insurance and preventative care. As the percent of the population of the state covered by insurance increases, the percent 
      engaging in preventative care also increases. When colored by immunization coverage, we see that most of the states with low coverage also have lower percentages of their population 
      covered by insurance and preventative care. 
    </p>
    <br>
    
    <h3>Data Preparation</h3>
   
    <p> 
    Clustering analysis requires the use of unlabeled numerical data. Unlabeled means that we have not included in the clustering analysis the labeled groupings. As such, for this analysis we 
    looked for clustering patterns between insurance and preventative care. We did not include immunization coverage in the models. Additionally, because clustering looks at the distance between 
    points, the features were standardized before analysis. To simplify the interpretation of the data, insurance status was flipped from uninsured to insured (100 - the percent 
    uninsured). Table 2 shows the original and standardized distributions of the features.  <br>
    <br>
    <b>Table 2</b><br>
    <img src="images/Q2_insured_pcare_good_immun_features.png" alt="Q2 Good Immunization features" width="1200"><br><br>
    <br>
    Due to the data use agreement, these data are stored on a private repository here:
      <a href="https://github.com/vt-art/NSCH_AHR_Data/blob/main/df_state_std_cluster.csv" target="_blank" rel="noopener noreferrer">
        df_state_std_cluster.csv.  
      </a>
      
    </p>

    <br>
    <h3>Code</h3>
   
    <p> 
      All programming was completed in Python using the program 
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/3_NSCH_AHR_Cluster_Analysis.ipynb" target="_blank" rel="noopener noreferrer">
        3_NSCH_AHR_Cluster_Analysis.
      </a>
      After the data are read in and the features standardized, the next step of the code is finding the best value for k. From here, the program completes K-Means clustering 
      with the determined value of k. The code iteratively shows how the clusters stabilize over the iterations. Next the clusters are compared to the true values for immunization status. 
      The accuracy is assessed and the confusion matrix is generated. <br>
      <br>
      After completing K-Means, the next section of the program focuses on hierarchical clustering for the same features and comparison to the same outcome. The model uses the Agglomerative 
      or bottom-up method. Cosine Similarity is implemented to measure distance and the average linkage is used. Once the dendrogram is produced, it is cut at two clusters and the clusters 
      are compared to the true values for immunization status. The accuracy is assessed and the confusion matrix is generated. 
    </p>

    <br>
    <h3>Results</h3>
   
    <p> 
      States were evently split on insurance coverage with 25/51 (49%) having low coverage and 26/51 (51%) having medium or high coverage. Clustering appeared to work well for these data. Figure 11 shows how the 
      groupings varied when attempting k=2-10 clusters. On visual inspection, 2-3 clusters look the best.<br>
      <br>
      <b>Figure 11</b><br>
      <img src="images/Q2_insured_pcare_good_immun_k.png" alt="Q2 Good Immunization k" width="1200"><br><br>

      Visual inspection of the clusters was followed by applying the elbow and Silhouette methods to selecting k. The elbow method (Figure 12) was inconclusive, as the graph 
      descends without a clear "elbow". Conversely, the Silhouette method showed a clear winner with two clusters having the highest value (Figure 13). This is in line with 
      the visual inspection of the clusters.<br>
      <br>
      <b>Figure 12</b><br>
      <img src="images/Q2_insured_pcare_good_immun_elbow.png" alt="Q2 Good Immunization elbow" width="1200"><br><br>
      
      <br>
      <b>Figure 13</b><br>
      <img src="images/Q2_insured_pcare_good_immun_silhouette.png" alt="Q2 Good Immunization silhouette" width="1200"><br><br>

      Once two clusters were identified for k, K-Means was completed. Figure 14 shows how the clusters stabilized after the first iteration. The bottom panels of the figure show how 
      the clusters generated by K-Means analysis compare to the true values for immunization coverage. <br>
      <br>
      <b>Figure 14</b><br>
      <img src="images/Q2_insured_pcare_good_immun_kmeans.png" alt="Q2 Good Immunization kmeans" style="width: 1200px; height: auto;"><br><br>
      The corresponding confusion matrix is below:<br>
      [[17  8]<br>
      [ 7 19]]<br>
      <br>
      The confusion matrix illustrates that the accuracy is 0.7059 and the misclassification rate is 0.2941. This is visually represented in Figure 15, where we can see that the 
      clusters differentiated well on the outer edges, while performing less well where the clusters intersect.<br>
      <br>
      <b>Figure 15</b><br>
      <img src="images/Q2_insured_pcare_good_immun_kmeans_correct.png" alt="Q2 Good Immunization kmeans correct" width="1200"><br><br>
      
      <br>
      Next, we completed the same analysis using hierarchical clustering techniques. From the dendrogram (Figure 16), we see that the clusters differentiate well at around two clusters, 
      which is what we found with the Silhouette method in K-Means.<br>
      <br>
      <b>Figure 16</b><br>
      <img src="images/Q2_insured_pcare_good_immun_dendrogram.png" alt="Q2 Good Immunization dendrogram" width="1200"><br><br>
       
      Figure 17 illustrates the comparison of the hierarchical clusters with the true values for immunization coverage.<br>
      <br>
      <b>Figure 17</b><br>
      <img src="images/Q2_insured_pcare_good_immun_hc.png" alt="Q2 Good Immunization hc" width="1200"><br><br>

      The corresponding confusion matrix is below:<br>
      [[16  9]<br>
      [ 4 22]]<br>
      <br>
      The confusion matrix illustrates that the accuracy is 0.7451 and the misclassification rate is 0.2549. As such, hierarchical clustering performed better than K-Means. Figure 15 
      shows the clusters which were correctly identified and those that were missed. As with K-Means, the clusters on the further sides were identified correctly, while the area of 
      intersection was more problematic.<br>
      <br>
      <b>Figure 18</b><br>
      <img src="images/Q2_insured_pcare_good_immun_hc_correct.png" alt="Q2 Good Immunization hc correct" width="1200"><br><br>
            
    </p>    

    <br>
    <h3>Conclusions</h3>
   
    <p> 
      K-Means and hierarchical clustering showed that there are unique similarities within states that have similar rates of insurance and preventative care coverage. States clustering together 
      with lower coverage tended to also have lower immunization coverage. Those with medium to high insurance and preventative care rates clustered together. This group tended to also have 
      medium to high immunization coverage. These results are in-line with the visual inspection of the data which showed a positive correlation between insurance and preventative care, as well as 
      higher immunization rates for states with higher insurance and preventative care coverage.  These results identify a gap for states with low coverage. Making care accessible through insurance 
      and preventative care appears to be related to higher childhood immunization rates. 
    </p>

    <br>
    <h3>References</h3>
    
    <p>
      Davis, Alex. Towards Data Science. A Guide to Clustering Algorithms: An overview of clustering and the different families of clustering algorithms. Sep 6, 2024
      <a href="https://towardsdatascience.com/a-guide-to-clustering-algorithms-e28af85da0b7/" target="_blank" rel="noopener noreferrer">
        Website link.
      </a>
  </p>
  </div>

  <div id="PCA (Principle Component Analysis)" class="tab-content">
    
    <h1>Principal Component Analysis (PCA)</h1>
    
    <img src="Website_Pic12.JPG" alt="PCA image." width="1200"> 
    
    <br>
    <h3>Overview</h3>
    
    <p>
      Many fields, such as medicine, finance and entertainment, generate enormous amounts of data with hundreds or thousands of variables. When modeling these data, 
      one might expect that having more features would provide deeper insights into the data. However, too many features pose several challenges, including 
      overfitting, computational complexity, and difficulty visualizing. Additionally, as the number of features increase, the 
      average distance between data points increases, as illustrated by Andreoni below. These challenges make it difficult to discern patterns in high-dimensional data. <br>
      
      <br>
      <b>Illustration of Average Distance between Data Points by the Number of Dimensions (Source: Andreoni, 2024)</b><br>
      <img src="images/Andreoni_Distance_by_Number_of_Dimensions.png" alt="Andreoni_Distance_by_Dimensions_TDS" style="width: 1200px; height: auto;"><br><br>

      Dimensionality reduction, or decreasing the total number of features while maintaining as much information as possible, provides a solution for the challenges of high-dimensional 
      data. Several methods of dimensionality reduction exist including methods of feature selection and feature extraction. With feature selection, the data are subset to the primary 
      variables of interest in the dataset without altering the features. Conversely, with feature extraction the variables are combined or transformed to create new variables, which 
      maintain the important information in the data. Methods for feature selection and extraction (Ref: GeekforGeeks) include, but are not limited to:<br>
      <ul>
        <li>Filtering: Ranking features by relevance. </li>
        <li>Wrapping: Keeping features based on model performance. </li>
        <li>Embedding: Features selected per model training outcomes.</li> 
        <li>Backward Feature Elimination: The initial model is the full model of all features. Unimportant variables are iteratively removed until only the most impactful covariates remain.</li>
        <li>Forward Feature Selection: This is the reverse of backward feature elimination. It begins with the intercept-only model and incrementally adds only the features that improve model performance.</li>
        <li>Random Forest: This ensemble model uses decision trees to pick the most important features.</li>
        <li>Linear Discriminant Analysis: Determines the features which in combination separate the data into different classes.</li>
        <li>Principal Component Analysis: Variables are converted into uncorrelated principal components.</li>
      </ul>
      <br>
      For this analysis, we are using Principal Component Analysis (PCA). PCA distills the data down into principal components, which are orthogonal to one another. These new, uncorrelated features are then 
      projected onto a hyperplane. In the simple illustration below by Andreoni, we can see that PCA transforms a two-dimensional space into a single dimension. 
    
      <br><br>
      <b>Illustration of Principal Component Analysis in a 2D Space (Source: Andreoni, 2024)</b><br>
      <img src="images/Andreoni_PCA.png" alt="Andreoni_PCA_TDS" style="width: 1200px; height: auto;"><br><br>

      The mathematical elements of principal components are their eigenvalues and eigenvectors. Eigenvectors are vectors that when scaled remain on the same line (i.e. they either do not 
      change their direction or they flip to the opposite direction). The scaling factor for the eigenvectors is the corresponding eigenvalue, which is the magnitude of the scaling. 
    
    </p>
    
    <br>
    <h3>Data Prep</h3>
    
    <p> 
      PCA requires the use of unlabeled numerical data. Unlabeled means that we have not included in the analysis the labeled groupings. For this analysis we included ten continuous variables, specifically
      the following state-level features were kept and standardized: percent of children receiving at least one preventative care visit, percentage of children in excellent or very good health, percent of 
      children who had a place they usually went to for healthcare, percentage of the population younger than age 18, percentage of adults age 25 and older with at least a high school diploma or equivalent, 
      percentage of households living at or above the federal poverty level, number of active primary care providers per 100,000 population, public health funding per capita, percentage of the population 
      covered by private or public health insurance, and sum of the social support and engagement measures. Because we were interested in binary immunization coverage as an outcome, we did not include this 
      variable in the PCA. Figure 19 illustrates the pairwise distributions of the variables colored by immunization coverage. Also provided is a heat map of the standardized distributions of the features 
      (Figure 20).
    </p>
     
    <br>
    <b>Figure 19</b><br>
    <img src="images/Q2_good_immun_pairwise_scatter.png" alt="Q2 pairwise scatter" width="1200"><br><br>

    <br>
    <b>Figure 20</b><br>
    <img src="images/Q2_PCA_heat.png" alt="Q2 heat" width="1200"><br><br>

    <p> 
      Using the scaled features, the principal components were calculated and added to the dataframe. Due to the data use agreement, these data are stored on a private repository here:
      <a href="https://github.com/vt-art/NSCH_AHR_Data/blob/main/df_state_std_PCA.csv" target="_blank" rel="noopener noreferrer">
        df_state_std_PCA.csv.  
      </a> 
      
    </p>
    
    <br>
    <h3>Code</h3>
    
    <p> 
      The following Python program contains the code for the principal component analysis:
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/4_NSCH_AHR_PCA_Analysis.ipynb" target="_blank" rel="noopener noreferrer">
        4_NSCH_AHR_PCA_Analysis.
      </a>
      The first step of the code is to read in the state-level data from NSCH and AHR. Next, the following continuous state-level features were kept and standardized: percent of children receiving at least one 
      preventative care visit, percentage of children in excellent or very good health, percent of children who had a place they usually went to for healthcare, percentage of the population younger than 
      age 18, percentage of adults age 25 and older with at least a high school diploma or equivalent, percentage of households living at or above the federal poverty level, number of active primary care 
      providers per 100,000 population, public health funding per capita, percentage of the population covered by private or public health insurance, and sum of the social support and engagement measures. <br>
      <br>
      Next, Eigenvectors, eigenvalues and loadings were calculated using both numpy and sklearn. Scree, biplots and scatter plots of the principal components were produced, as well as tables and figures of the 
      cumulative variance and loadings. Lastly, the program joins the PCA data with the standardized features, outputting a CSV file of the resulting dataframe.<br>            
    </p>
    
    <br>
    <h3>Results</h3> 
    
    <p> 
      Eigenvectors, eigenvalues and loadings were calculated two different ways and compared. First, using numpy the covariance matrix for the features was generated and the eigenvalues and eigenvectors calculated 
      using numpy linalg.eig(). These were sorted in descending order by eigenvalue. The loadings were calculated using the equation: loading = eigenvectors_sorted * np.sqrt(eigenvalues_sorted). The same calculations
      were repeated using sklearn PCA() to complete the principal component analysis, specifically:<br>
      <ul>
        <li>eigenvalues_PCA = pca.explained_variance_</li>
        <li>eigenvectors_PCA = pca.components_.T</li>
        <li>loading_PCA = pca.components_.T * np.sqrt(pca.explained_variance_)</li>
      </ul>
      <br>
      The eigenvalues calculated using numpy were identical to sklearn.decomposition PCA(). The sign of the eigenvectors for PC4 and PC10 are opposite between the two methods. Otherwise, the eigenvectors and loadings 
      are the same between the methods.
      <br>
      Scree plots indicated that PC1 accounted for approximately 43% of the variation in the data, followed by PC2 with 23% of the variance (data not shown). When looked at cumulatively, PC1-PC7 accounted for 95% of 
      the total data variation (Figure 21). Meeting this threshold with seven principal components allows us to reduce our dimensions from 10 to seven.
    </p>
    
    <br>
    <b>Figure 21</b><br>
    <img src="images/Q2_PCA_cumulative_variance.png" alt="Q2 PCA Variance" width="1200"><br><br>

    <p>
      To better understand the direction, magnitude and features involved in each principal component, we completed a loading analysis. Table 3 provides the loadings for each principal component and feature. 
      Interestingly, the only feature positively correlated with PC1 is the state population under age 18. All other variables are negatively correlated with PC1. We see greater variability in the loadings for 
      PC2 with excellent or good health, a place for care, completing high school, above the poverty line, engagement in the community and the population less than 18 showing positive correlation with PC2. <br>      
    </p>  
    <br>
    <b>Table 3</b><br>
    <!-- Embed table as iframe -->
    <iframe src="images/PCA_loadings.html" width="100%" height="300" style="border:none;"></iframe></b><br>

    <p>
      When we look at the biplot for PC1 and PC2, we find that PC1 uniquely separates states with large numbers of children under age 18 that also have lower values for primary care providers, preventative care and 
      insurance (Figure 22). States in this quadrant with positive PC1 and positive PC2 include many Southern and Southwest states - South Carolina, Georgia, Arkansas, Oklahoma, Texas and Nevada, as well as  
      Indiana and New Jersey (Figure 23). The states in the upper-left quadrant where PC1 is negative and PC2 is positive, have higher levels of health, income, completing high school, places to regularly receive 
      care and engagement. However, this same quadrant has lower levels for features related to health care access (primary care providers, preventative care and insurance). This suggests that although these states 
      may have better education and less poverty, there may be gaps in health care coverage. Western states (Utah, Idaho, Colorado, Wyoming, Montana, Washington) and mid-Western states (South Dakota, North Dakota, 
      Minnesota, Kansas, Nebraska, Iowa, Illinois, and Ohio) primarily make up this group. Arkansas, Virginia and Maryland are also included. When both PC1 and PC2 are negative (bottom-left quadrant), we see that 
      states in this quadrant are higher in primary care providers, preventative care and insurance. These states are lower in population under 18 with higher completion of high school and percentage 
      above the poverty line, suggesting that what makes them unique is the high health care coverage. States in the last quadrant where PC1 is positive, but PC2 is negative have higher population < 18 with some 
      healthcare services available and weaker education and economic measures.      
    </p>  
    
    <br>
    <b>Figure 22</b><br>
    <img src="images/PCA_2D_loadings.png" alt="PC Biplot" width="1200"><br><br>

    <br>
    <b>Figure 23</b><br>
    <img src="images/PC1_PC2_Quadrants.png" alt="PC Quads" width="1200"><br><br> 
    
   
    <p>
      Looking at a 3D depiction of PC1, PC2, and PC3, we see that coloring by immunization coverage illuminates an interesting pattern in the data. Specifically, higher values of PC1 
      and PC2 with lower values of PC3 align with lower immunization coverage (Figure 24). Conversely, lower values of PC1 and PC2 have medium to high immunization coverage. These 
      observations consistently follow the loading and quadrant analyses above.
    </p>  
   
    <br>
    <b>Figure 24</b><br>
    <img src="images/Q2_good_immun_3PC.png" alt="Q2 Good Immunization 3 PC" width="1200"><br><br>
    
    <br>
    <h3>Conclusions</h3>
   
    <p> 
      Through PCA, we found that states with large numbers of children under the age of 18 that also have lower values for primary care providers, preventative care and 
      insurance experience lower immunization coverage. As with the cluster analysis, these results support that higher immunization rates occur in states with higher insurance and preventative care coverage. 
      These results identify a gap for states with high proportion of children and a low proportion of preventative care, providers and insurance coverage.      
    </p>

    <br>
    <h3>References</h3>

    <p>
      1. Andreoni, Riccardo. Dimensionality Reduction Made Simple: PCA Theory and Scikit-Learn Implementation: 
      Tame the Curse of Dimensionality! Learn Dimensionality Reduction (PCA) and implement it with Python and Scikit-Learn. 
      Towards Data Science. Feb 7, 2024.
      <a href="https://towardsdatascience.com/dimensionality-reduction-made-simple-pca-theory-and-scikit-learn-implementation-9d07a388df9e/" target="_blank" rel="noopener noreferrer">
        Website link.
      </a>
      <br><br>
      2. Sena, Marcus. Principal Component Analysis Made Easy: A Step-by-Step Tutorial. Implement the PCA algorithm from scratch with Python. 
      Towards Data Science. Jun 8, 2024.
      <a href="https://towardsdatascience.com/principal-component-analysis-made-easy-a-step-by-step-tutorial-184f295e97fe/" target="_blank" rel="noopener noreferrer">
        Website link.
      </a>
      <br><br>
      3. Feature Selection Techniques in Machine Learning. GeeksforGeeks. Aug 30, 2025.  
      <a href="https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/" target="_blank" rel="noopener noreferrer">
        Website link.
      </a>      
      <br><br>
      4. What is Feature Extraction. GeeksforGeeks. Aug 30, 2025.  
      <a href="https://www.geeksforgeeks.org/machine-learning/what-is-feature-extraction/" target="_blank" rel="noopener noreferrer">
        Website link.
      </a>
      <br><br>
      5. Mueller, Vincent. Eigenvalues and eigenvectors in PCA: What do they tell us about our data? Sep 18, 2021.  
      <a href="https://towardsdatascience.com/eigenvalues-and-eigenvectors-378e851bf372/" target="_blank" rel="noopener noreferrer">
        Website link.
      </a>
      <br><br>
    
    </p> 
    
  </div>

  <div id="NaiveBayes" class="tab-content">
      
    <h2>Naïve Bayes</h2>

    <img src="Website_Pic20.JPG" alt="NaiveBayes image."
     style="float: right; margin: 0 0 10px 20px; width: 400px;">
    
    <br>
    <h3>Overview</h3>
     <p>
       Naïve Bayes classification is a method of supervised learning where the model predicts the target variable by calculating the probability of each class. The method 
       relies on Bayes’ Theorem for the calculation of conditional probabilities, which states:
     </p>

     <p>
       \[
         P(C \mid X) = \frac{P(X \mid C) \cdot P(C)}{P(X)}
       \]
     </p>

     <p>
       In terms of our target class and the features, we have:</p>
     <ul>
       <li> \(P(C|X)\) is the posterior probability of class C, given the features X. This is the conditional probability of interest. </li>
       <li> \(P(X|C)\) is the likelihood of features X, given class C. This quantity is often known or easier to calculate than \(P(C|X)\). 
            \(P(X|C)\) = \(P(x_1, x_2, x_3,…,x_n|C) = \prod_{i=1}^{n}P(x_i|C)\) </li>
       <li> \(P(C)\) is the prior probability of class C and is calculated as the number in class C divided by the number in all classes. </li>
       <li> \(P(X)\) is the marginal probability of the features and acts as a normalizing constant. </li>
     </ul>
     
     <p>
       Naïve Bayes is used to find the class C that maximizes the posterior (\(P(C|X)\)). Since \(P(X)\) is the same for all classes, we can ignore the denominator in the 
       classification. Naïve Bayes assumes that all features (\(x_1, x_2, x_3,…,x_n\)) are conditionally independent given the class label. The algorithm stores probability 
       distributions for each class and feature. The type of distribution depends on the type of features, specifically:
     </p>

     <ul>
       <li> Multinomial Naïve Bayes: discrete features (e.g. word counts) </li>
       <li> Bernoulli Naïve Bayes: binary features (e.g. Yes/No, Present/Absent, True/False) </li>
       <li> Gaussian Naïve Bayes: continuous features (e.g. test scores) </li>
     </ul>

    <br>
    <b>Illustration of three main types of Naïve Bayes Classifiers (Source: Baladram, 2024)</b><br>
    <img src="images/Baladram_Naive_Bayes_Approaches.png" alt="Baladram_Naive_Bayes_Approaches" width="600"><br><br>
    
    <p>
      It is possible that a given class does not contain any events. Since we are taking the product by each feature, a zero probability for a given feature would result 
      in a total probability of zero. As such, we implement Laplace Smoothing which adds one to the numerator to prevent zero probabilities. For example, the probability 
      that a word belongs to a given class then becomes:
    </p>

    <p>
      \[
         P(\text{word belongs to class}) = \frac{\text{count of the word in the class} + 1}{\text{total words in the class} + \text{magnitude of the full set of words}}
      \]
    </p>

    <p>
      As a classification algorithm, Naïve Bayes has many uses, including sentiment analysis, image recognition, and recommendation systems. Naïve 
      Bayes is also used for predicting medical diagnoses from symptom data. Additionally, it may be used for text classification to aid in spam filtering or 
      documentation categorization.  
    </p>
    
    <br>
    <h3>Data Prep</h3>
    
    <p> 
      Both multinomial and Bernoulli Naïve Bayes were preformed. As explained above, multinomial Naïve Bayes requires discrete features (such as word counts). Although our data did not really fit the 
      required type. We attempted multinomial Naïve Bayes in line with the project guidelines. From the family-level data from NSCH, we selected count variables. Specifically, the following features were 
      kept and missing values were replaced with the mode: five-level health status, five-level child's screen time usage, child's age, three-level family food and cash assistance, number of family members 
      in the household, and highest-level of adult education for the family (four-levels). The target variable of inadequate hours of sleep for age was also kept and replaced with the mode if missing. 
      Figure 25 shows the features selected for multinomial Naïve Bayes by the adequacy of sleep among teenagers. 
    </p>

    <br>
    <b>Figure 25</b><br>
    <img src="images/Q9_AdeqSleep_MNB_features.png" alt="Q9_AdeqSleep_MNB_features" width="1200"><br><br>

    <p>
      Features, target and sample weights are split into training and test sets. The split worked well for a relatively even distribution of the target variable, as shown
      in Table 4. The training and test data are disjoint because these data sets serve different purposes. The training data are used to train the model and help it to 
      learn patterns from the data. The test data are used to evaluate the model's performance on unseen data. If the model is tested on the same data it was trained on, it 
      may appear to perform better than it actually does, which could lead to misuse of the model. Tables 5 and 6 provide the first five rows of data for the training and testing data, respectively. 
    </p> 
    
    <br>
    <b>Table 4</b><br>
    <img src="images/MNB_Train_Test_Target_Split.png" alt="MNB train test split" width="400"><br><br>
    
    <br>
    <b>Table 5</b><br>
    <img src="images/MNB_Train_Data_Head.png" alt="MNB train head" width="1200"><br><br>
    
    <br>
    <b>Table 6</b><br>
    <img src="images/MNB_Test_Data_Head.png" alt="MNB test head" width="1200"><br><br>
    
    <p>
      The Bernoulli Naïve Bayes analysis required binary features. Family-level data from NSCH for the following features were kept and missing values were replaced with 
      the mode: child's screen time usage, child's age, housing instability, family food and cash assistance, adequate and continuous insurance, health status, preventative care 
      visits, and a place to get health care. Dummy variables were created for the features. The reference categories were NOT dropped, as all categories are needed to 
      complete the Naïve Bayes analysis. The target variable of inadequate hours of sleep for age was also kept and replaced with the mode if missing. 
      The raw features by adequacy of sleep among teenagers are provided in Figure 26. 
    </p>
    
    <br>
    <b>Figure 26</b><br>
    <img src="images/Q9_AdeqSleep_BNB_features.png" alt="Q9_AdeqSleep_BNB_features" width="1200"><br><br>


    <p>
      Features, target and sample weights are split into training and test sets. The split worked well for a relatively even distribution of the target variable, as shown
      in Table 7. Tables 8 and 9 provide the first five rows of data for the training and testing data, respectively. 
    </p> 
    
    <br>
    <b>Table 7</b><br>
    <img src="images/BNB_Train_Test_Target_Split.png" alt="BNB train test split" width="400"><br><br>
    
    <br>
    <b>Table 8</b><br>
    <img src="images/BNB_Train_Data_Head.png" alt="BNB train head" width="1200"><br><br>
    
    <br>
    <b>Table 9</b><br>
    <img src="images/BNB_Test_Data_Head.png" alt="BNB test head" width="1200"><br><br>

    <p>
      Due to the data use agreement, these data are stored on a private repository. The state-level data  used in the multinomial Naïve Bayes are here: 
      <a href="https://github.com/vt-art/NSCH_AHR_Data/blob/main/NSCH_AHR_state.csv" target="_blank" rel="noopener noreferrer">
        NSCH_AHR_state.csv.  
      </a> 

      The family-level data used in the Bernoulli Naïve Bayes are here:
      <a href="https://github.com/vt-art/NSCH_AHR_Data/blob/main/NSCH_fam.csv" target="_blank" rel="noopener noreferrer">
        NSCH_fam.csv.  
      </a> 

    </p>
    
    <br>
    <h3>Code</h3>

    <p> 
      The following Python program contains the code for the Multinomial Naïve Bayes analysis:
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/5a_NSCH_Multinonial_Naive_Bayes_Analysis.ipynb" target="_blank" rel="noopener noreferrer">
        5a_NSCH_Multinonial_Naive_Bayes_Analysis.
      </a>      
      
      The first step of the code is to read in the family-level data from NSCH. Next, the following features were kept and missing values were replaced with the mode: 
      five-level health status, child's screen time usage, child's age, three-level family food and cash assistance, number of family members in the household, and 
      highest-level of adult education for the family. The target variable of inadequate hours of sleep for age was also kept and replaced with the mode if missing. 
      Features, target and sample weights are split into training and test sets. <br>
      <br>
     
      Next, the Multinomial Naïve Bayes classifier is instanciated and fit with the above target, feature and sample weight variables using the training data. The confusion 
      matrix was assessed and the model performed poorly at a 0.5 threshold. As such, the optimal threshold was assessed from accuracy, recall and f-1 scores. After determining 
      a threshold of 0.3 was ideal, the model was refit at this level. The following hyperparameters were used: 'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 
      'force_alpha': True. Measures of model performance are calculated, including weighted accuracy, recall, f1-score and ROC/AUC for the test set. This follows with the 
      calculation of log probabilities for the features. Finally, partial dependency plots are created for each feature.
    </p>
        
    <p> 
      The following Python program contains the code for the Bernoulli Naïve Bayes analysis:
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/5b_NSCH_Bernoulli_Naive_Bayes_Analysis.ipynb" target="_blank" rel="noopener noreferrer">
        5b_NSCH_Bernoulli_Naive_Bayes_Analysis.
      </a>      
      
      The first step of the code is to read in the family-level data from NSCH. Next, the following features were kept and missing values were replaced with the mode: 
      child's screen time usage, child's age, housing instability, family food and cash assistance, adequate and continuous insurance, health status, preventative care 
      visits, and a place to get health care. Dummy variables were created for the features. The reference categories were NOT dropped, as all categories are needed to 
      complete the Naïve Bayes analysis. The target variable of inadequate hours of sleep for age was also kept and replaced with the mode if missing. Features, target 
      and sample weights are split into training and test sets. <br>
      <br>
     
      Next, the Bernoulli Naïve Bayes classifier is instanciated and fit with the above target, feature and sample weight variables using the training data. The following 
      hyperparameters were used: 'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True. Measures of model performance are calculated, 
      including weighted accuracy, recall, f1-score and ROC/AUC for the test set. This follows with the calculation of log probabilities for the features. Finally, partial 
      dependency plots are created for each feature.      
              
    </p>
    
    <br>
    <h3>Results</h3> 
    
    <p> 
      Of the 15,391 teenages who participated in NSCH, 4272 (27.8%) reported inadequate sleep. The weighted Multinomial Naïve Bayes classifier was first run with the default threshold of 0.5. As shown in Figure 27, 
      the model performed poorly with zero true positives detected. As such, we conducted an analysis of the accuracy, recall and f1-scores by various thresholds (Figure 28 and 29) and determined that a threshold 
      of 0.3 provided the best balance of these measures.  
    </p>

    <br>
    <b>Figure 27</b><br>
    <img src="images/Q9_AdeqSleep_MNB_CM_Original.png" alt="Q9_AdeqSleep_MNB_CM_Original" width="1200"><br><br>

    <br>
    <b>Figure 28</b><br>
    <img src="images/Q9_AdeqSleep_MNB_Threshold_Tuning.png" alt="Q9_AdeqSleep_MNB_Threshold_Tuning" width="1200"><br><br>

    <br>
    <b>Figure 29</b><br>
    <img src="images/Q9_AdeqSleep_MNB_PrecRecall.png" alt="Q9_AdeqSleep_MNB_PrecRecall" width="1200"><br><br>

    <p>
      The multinomial Naïve Bayes model was updated with a threshold of 0.3, rerun and assessed for performance. The updated model performed better (Figure 30), although 
      there were more false positive results, as one would expect with a threshold of 0.3. The accuracy, f1-score and recall of the model were 0.68, 0.25 and 0.18, 
      respectively. The area under the curve was only 0.56, or slightly better than chance (Figure 31).
    </p>
    
    <br>
    <b>Figure 30</b><br>
    <img src="images/Q9_AdeqSleep_MNB_CM_ReviseThreshold.png" alt="Q9_AdeqSleep_MNB_CM_ReviseThreshold" width="1200"><br><br>

    <br>
    <b>Figure 31</b><br>
    <img src="images/Q9_AdeqSleep_MNB_ROC.png" alt="Q9_AdeqSleep_MNB_ROC" width="1200"><br><br>

    <p>
      To better understand the relationship between the features and the target variable, we calculated log-probabilities for each feature. A positive log-probability 
      score indicates that the feature is more associated with class 1 (inadequate sleep). A negative score means it is more associated with class 0 (adequate sleep).
      The magnitude of the score shows how influential the feature is. As seen in Figure 32, the child having poorer health status and greater screen time are associated 
      with inadequate sleep, while care givers having greater education and larger family size are associated with adequate sleep. We verified these relationships with 
      partial dependency plots (data not shown).
    </p>  
    
    <br>
    <b>Figure 32</b><br>
    <img src="images/Q9_AdeqSleep_MNB_LogProb.png" alt="Q9_AdeqSleep_MNB_LogProb" width="1200"><br><br>

    <p>
      In addition to a multinomial Naïve Bayes analysis, we also completed a Bernoulli Naïve Bayes analysis. This approach appeared to work much better with our available 
      data. Creating dummy variables for multi-level features allowed us to differentiate the influence of the groupings within the features. The confusion matrix is provided 
      in Figure 33. Although the accuracy was good at 0.70, the f1-score (0.23) and recall (0.15) were poor. As illustrated by the ROC-curve in Figure 34, the area under the curve was 
      0.66.
    </p>
    
    <br>
    <b>Figure 33</b><br>
    <img src="images/Q9_AdeqSleep_BNB_CM.png" alt="Q9_AdeqSleep_BNB_CM" width="1200"><br><br>

    <br>
    <b>Figure 34</b><br>
    <img src="images/Q9_AdeqSleep_BNB_ROC.png" alt="Q9_AdeqSleep_BNB_ROC" width="1200"><br><br>
    
    <p>
      We also looked at log probabilities for the features and saw interesting patterns emerge (Figure 35). Younger children (ages 13 and 14) and children with less screen time 
      per day (0-2 hours) were associated with having adequate sleep for their age. Conversely, older teens (ages 16 and 17), children with greater screen time per day 
      (3 or more hours), children experiencing housing instability, and children with poorer health were associated with having inadequate sleep for age. We confirmed these 
      associations by reviewing partial dependency plots for all features (data not shown).
    </p>
    
    <br>
    <b>Figure 35</b><br>
    <img src="images/Q9_AdeqSleep_BNB_LogDiff.png" alt="Q9_AdeqSleep_BNB_LogDiff" width="1200"><br><br>
   
    <br>
    <h3>Conclusions</h3>
   
    <p> 
      The American Academy of Sleep Medicine recommends that to promote optimal health, teens should regularly sleep eight to 10 hours per 24-hour period (Ref: Paruthi). 
      This Naïve Bayes analysis found that older teens, teens using screens for 3 or more hours per day, those with poorer health, and those with housing instability 
      are more at risk for inadequate sleep. Helping these groups obtain enough sleep could improve their overall physical and mental health.
    </p> 

    <h3>References</h3>
    
    <ul> 
        <li>Baladram, S. Bernoulli Naive Bayes, Explained: A Visual Guide with Code Examples for Beginners. Unlocking predictive power through Yes/No probability. 
          Towards Data Science. August 2024. <br>
          Available from: https://towardsdatascience.com/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6/ </li>
        <li>Yıldırım, S. Naive Bayes Classifier – Explained. Theory and implementation with scikit-learn. Medium, Towards Data Science Archive. Feb 2020.<br>
           Available from: https://medium.com/data-science/naive-bayes-classifier-explained-50f9723571ed </li>
        <li>Mocquin, Y. Multinomial Naive Bayes Classifier. A complete worked example for text-review classification. Towards Data Science. March 2024.<br>
           Available from: https://towardsdatascience.com/multinomial-naive-bayes-classifier-c861311caff9/</li>
        <li> Paruthi, S., Brooks, L,  D'Ambrosio, C, et. al. Recommended Amount of Sleep for Pediatric Populations: A Consensus Statement of the American Academy of Sleep 
          Medicine. Journal of Clinical Sleep Medicine (2016). https://doi.org/10.5664/jcsm.5866 </li>
      </ul>
  
    
  </div>

  <div id="DecTrees" class="tab-content">
    <h2>Decision Trees</h2>

    <img src="Website_Pic6.jpg" alt="DecTrees image"  width="1200">
    
       
    <br>
    <h3>Overview</h3>
   
    <p> 
      Decision Trees are a supervised machine learning algorithm for classification analysis. The root node of the tree contains the entire dataset (refer to the 
      illustration of the tree structure). From the root node, the tree branches out to decision nodes until a leaf or final class assignment node is met. Leaf nodes may 
      be pure (i.e. all datapoints in the leaf belong to the same class) or impure (i.e. the data in the leaf are mixed classes). 
    </p>

    <br>
    <b>Illustration of the Structure of Decision Trees (Source: Dash, 2022)</b><br>
    <img src="images/Dash_DT_Structure.png" alt="DT Structure" width="1200"><br><br>

    <p>
      Decision nodes contain conditions by which the data are split. The algorithm attempts every possible split and uses either information gain or GINI to determine the 
      best split. Specifically, the goal is to implement the condition that makes the data and each child node the most predictable or homogenous in the target variable.  
    </p>

    <p>      
      We can measure how mixed the data are by calculating the entropy before and after the split, and then calculate the information gain. Entropy is calculated as follows, 
      where "s" is the subset of data, "k" is the number of possible classes (e.g. Yes/No), and P<sub>i</sub> is the proportion in class i:
    </p>
    
     <p>
       \[
         Entropy = H(s) = - \sum_{i=1}^{k} P_i*\log_2(P_i)
       \]
     </p>

    <p>
      Entropy ranges from zero to one inclusive. Entropy of zero indicates perfect purity, where all datapoints are from the same class, while entropy of 1 is perfect 
      impurity (i.e. a 50/50 split between classes). As the depth of the tree increases the entropy decreases. With these calculations of entropy we can calculate the 
      information gain. 
    </p>

    <p>
       \[
         \text{Information Gain} = \text{entropy of the parent node - entropy of the child nodes}
       \]
    </p>

    <br>
    <b>Illustration of Decision Tree Slitting (Source: Modified from Dash, 2022)</b><br>
    <img src="images/Dash_DT_Splitting.png" alt="DT Splitting" width="1200"><br><br>

    <p>
      The image above illustrates the calculation of entropy and information gain for the decision tree. The entire system has an entropy of 1 or perfect impurity because 
      the data are split 50/50 at the root node. The first split using the student's background reduces the entropy dramatically, since the computer science students all 
      passed and the students from other backgrounds all failed the test. These nodes in green are pure leaf nodes (i.e. entropy = 0). Since math students still have a mix 
      of outcomes, the blue node is further split by whether or not the student is working. Lastly, the information gain of the tree is calculated as the entropy of the 
      system minus the average child node. The information gain is about 0.8.      
    </p>
    
    <p>
      Alternatively, we can determine the best split using the GINI index. The GINI Index calculates the probability of misclassifying a random instance. Because we don't 
      want to incorrectly classify a record, a lower GINI index is better. The formula for the GINI Index is as follows, where "j" is the number of possible classes 
      (e.g. Yes/No), and P<sub>i</sub> is the proportion of the class in the node:
    </p>
    
     <p>
       \[
         Gini = 1 - \sum_{i=1}^{j} P_i^2
       \]
     </p>
 
    <p>
      Since decision trees are easy to interpret and understand, they have a variety of uses. A recent article from Geeks for Geeks (Decision Trees) noted six applications 
      of Decision Trees, as follows:<br> 
      <ol>
        <li>Bankers determine whether to accept or reject a loan application based on factors like credit score, income, employment status and loan 
          history.</li>
        <li>Health providers may diagnose diseases considering factors like symptoms, biomarkers, family history, and demographics.</li>
        <li>Educators predict whether students will pass or fail given student attendance, study time and past performance. </li>
        <li>Businesses predict whether a customer will leave or stay based on purchasing history, behavioral choices and length of tenure.</li>
        <li>Fraud Detection: In finance, Decision Trees are used to detect fraudulent activities, such as credit card fraud. By analyzing past transaction data and patterns, Decision Trees can identify suspicious activities and flag them for further investigation.</li>
        <li>A decision tree can also be used to help build automated predictive models which have applications in machine learning, data mining and statistics.</li>
      </ol>
      
      </p>  
    
    <br>
    <h3>Data Prep</h3>
    
    <p> 
      This analysis uses the state-level data from NSCH and AHR. The following continuous state-level features were kept: 
      percentage of children in excellent or very good health, percent of children who had a place they usually went to for healthcare, 
      percent of children receiving at least one preventative care visit, percentage of adults age 25 and older with at least a high school diploma or equivalent, 
      percentage of the population younger than age 18, percentage of households living at or above the federal poverty level, 
      public health funding per capita, and sum of the social support and engagement measures. The target variable was constructed as good insurance coverage if the 
      state is both above the mean of states for residents having any insurance (Insured from AHR) AND above the mean of states for children having continuous and 
      adequate insurance (Insurance from NSCH).Figure 36 provides a heatmap of the features that were considered for the model.
    </p>

    <br>
    <b>Figure 36</b><br>
    <img src="images/Q6_heatmap_DT_features.png" alt="Q6_heatmap_DT_features" width="1200"><br><br>

    <p>
      Features and target are split into training and test sets. The split worked well for a relatively even distribution of the target variable, as shown
      in Table 10. The training and test data are disjoint because the training data are used to train the model and help it to 
      learn patterns from the data. The test data are used to evaluate the model's performance on unseen data. If the model is tested on the same data it was trained on, it 
      may appear to perform better than it actually does, which could lead to misuse of the model. Tables 11 and 12 provide the first five rows of data for the training and testing data, respectively. 
    </p> 
    
    <br>
    <b>Table 10</b><br>
    <img src="images/DT_Train_Test_Target_Split.png" alt="DT train test split" width="400"><br><br>
    
    <br>
    <b>Table 11</b><br>
    <img src="images/DT_Train_Data_Head.png" alt="DT train head" width="1200"><br><br>
    
    <br>
    <b>Table 12</b><br>
    <img src="images/DT_Test_Data_Head.png" alt="DT test head" width="1200"><br><br>

    <p>
      Data for the Random Forest analysis were prepared in a similar manner. Features of interest included: child's screen time usage, child's age, housing instability, family food and cash assistance, 
      adequate and continuous insurance, health status, preventative care visits, and a place to get health care. Dummy variables were created for the features and the reference categories were dropped. 
      The target variable of inadequate hours of sleep for age was also kept and replaced with the mode if missing. These data are from the family-level dataset and as such the sampling weights were also 
      included in the train-test split. Specifically, features, target and sample weights are split into training and test sets. 
    </p>

    <p>
      Due to the data use agreement, these data are stored on a private repository. The state-level data  used in the decision tree analysis are here: 
      <a href="https://github.com/vt-art/NSCH_AHR_Data/blob/main/NSCH_AHR_state.csv" target="_blank" rel="noopener noreferrer">
        NSCH_AHR_state.csv.  
      </a> 

      The family-level data used in the random forest analysis are here:
      <a href="https://github.com/vt-art/NSCH_AHR_Data/blob/main/NSCH_fam.csv" target="_blank" rel="noopener noreferrer">
        NSCH_fam.csv.  
      </a> 

    </p>
        
    <br>
    <h3>Code</h3>
    
    <p> 
      The following Python program contains the code for the decision tree analysis:
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/6_NSCH_AHR_Decision_Tree_Analysis.ipynb" target="_blank" rel="noopener noreferrer">
        6_NSCH_AHR_Decision_Tree_Analysis.
      </a>
      The first step of the code is to read in the state-level data from NSCH and AHR. Next, the following continuous state-level features were kept: 
      percentage of children in excellent or very good health, percent of children who had a place they usually went to for healthcare, 
      percent of children receiving at least one preventative care visit, percentage of adults age 25 and older with at least a high school diploma or equivalent, 
      percentage of the population younger than age 18, percentage of households living at or above the federal poverty level, 
      public health funding per capita, and sum of the social support and engagement measures. Social support and engagement measures is missing for Washington DC. This missing 
      value has been replaced with the median social support. The target variable was constructed as good insurance coverage if the 
      state is both above the mean of states for residents having any insurance (Insured from AHR) AND above the mean of states for children having continuous and 
      adequate insurance (Insurance from NSCH).<br>      
      <br>
      
      Next, the decision tree classifier is instanciated, fit with the above target, feature and sample weight variables, and tuned using the training data. For the 
      hyperparameter tuning a max_depth of 8, 9, 10, and None and min_samples_split of 2, 4, 6 were assessed with criterion='gini', splitter='best' and min_samples_leaf=1.      
      The resulting hyperparameters for the optimal model were: 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 
      'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 
      'random_state': 4567, 'splitter': 'best'. Measures of model performance are calculated, 
      including weighted accuracy, recall, f1-score and ROC/AUC for the test set. This follows with the calculation of feature importance based on mean decrease in impurity. 
      Additionally, the tree is plotted to assess how the data are split. Finally, partial dependency plots are created for each feature.<br> 
      <br>
      
      The Python program for the random forest analysis is located here:
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/7_NSCH_Random_Forest_Analysis.ipynb" target="_blank" rel="noopener noreferrer">
        7_NSCH_Random_Forest_Analysis.
      </a>
      The first step of the code is to read in the family-level data from NSCH. Next, the following features were kept and missing values were replaced with the mode: 
      child's screen time usage, child's age, housing instability, family food and cash assistance, adequate and continuous insurance, health status, preventative care 
      visits, and a place to get health care. Dummy variables were created for the features and the reference categories were dropped. The target variable of inadequate 
      hours of sleep for age was also kept and replaced with the mode if missing. Features, target and sample weights are split into training and test sets. <br>
      <br>
      Next, the random forest classifier is instanciated and fit with the above target, feature and sample weight (sample_weight = FWC_train) variables using the training data. 
      The following hyperparameters were used: 'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 
      'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 
      'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 4567, 'verbose': 0, 'warm_start': False. Measures of model performance are calculated, 
      including weighted accuracy, recall, f1-score and ROC/AUC for the test set. This follows with the calculation of feature importance based on mean decrease in impurity. In 
      order to gain an understanding of how the model was splitting features, one of the trees is plotted. Finally, partial dependency plots are created for each feature.      
    </p>    
    <br>
    <h3>Results</h3> 
    
    <p> 
      Few states have good insurance coverage for their residents with only 15/51 (29.4%) meeting this defined benchmark. The decision tree with the state-level outcome of good insurance was fit on the training set, 
      which included 35 states (~70%). The model performance was assessed on the test set of 16 states. As shown in Figure 37, the model performed well with an accuracy was 0.75. Both the f1-score (0.60) and 
      recall (0.60) indicate strong performance. Per capita spending on public health topped the important features with a feature importance score of 0.5 (Figure 38). Although to a lesser degree, other important 
      features for predicting good insurance included the proportion of the population above the poverty line, use of preventative care, health status of the population 
      and a supportive community.      
    </p>
  
    <br>
    <b>Figure 37</b><br>
    <img src="images/Q6_insurance_DT_CM.png" alt="Q6_insurance_DT_CM" width="1200"><br><br>

    <br>
    <b>Figure 38</b><br>
    <img src="images/Q6_insurance_DT_feature_importance.png" alt="Q6_insurance_DT_feature_importance" width="1200"><br><br>

    <p>
      The optimal decision tree had a max depth of 8. For illustrative purposes, Figure 39 shows the first few levels. As seen with the feature importance analysis 
      public health plays an important role in the classification by splitting the root node at less than or equal to $146 per person spent on public health. For context, 
      most states spend between $100-200 per capita on public health (median(P25, P75) = $123 (96.0, 156.5)). Branching to the left, 25 states spent $146 or less per person 
      on public health and 23 of these were classified as not good insurance. In contrast, ten states branched to the right because they spent more than $146 per person on public 
      health. Eight of these states were classified as meeting good insurance coverage.<br>
      <br>
      As illustrated by Figure 40, the ROC-curve of the test data yielded an area under the curve of 0.709. This indicates that the model has a good ability to 
      distinguish between states with and without good insurance coverage.
    </p>
        
    <br>
    <b>Figure 39</b><br>
    <img src="images/Q6_insurance_DT_tree_plot.png" alt="Q6_insurance_DT_tree_plot" width="1200"><br><br>
 
    <br>
    <b>Figure 40</b><br>
    <img src="images/Q6_insurance_DT_ROC.png" alt="Q6_insurance_DT_ROC" width="1200"><br><br>

    <p>    
      The random forest analyses did not perform well, resulting in an accuracy of 0.57, which is only marginally better than chance (data not shown). Additionally, the f1-score of 0.39 and recall score of 0.48 were 
      poor. 
    </p>
      
    <br>
    <h3>Conclusions</h3>
   
    <p> 
      The decision tree with the state-level outcome of good insurance found that per capita spending on public health of at least $147 per person delineated the data fairly well into states with and without good 
      insurance coverage. This has important implications for states hoping to bolster insurance coverage for their residents. Since the median public health spending is $123, on average states would only need to 
      increase their spending by approximately $24 per person in order to reach this threshold. Such an investment could provide residents with greater access to health coverage. According to the American Hospital 
      Association, "studies confirm that coverage improves access to care; supports positive health outcomes, including an individual’s sense of their own health and well-being; incentivizes appropriate use of health care resources; and reduces financial strain 
      on individuals, families and communities.      
    </p> 



    <h3>References</h3>
    
    <ul> 
        <li>Dash, S. Decision Trees Explained – Entropy, Information Gain, Gini Index, CCP Pruning. Though Decision Trees look simple and intuitive, there is nothing very 
          simple about how the algorithm goes about the process deciding on... Towards Data Science. November 2022. <br>
          Available from: https://towardsdatascience.com/decision-trees-explained-entropy-information-gain-gini-index-ccp-pruning-4d78070db36c/ </li>
        <li> Decision Trees. Geeks for Geeks. June 2025. <br>
          Available from: https://www.geeksforgeeks.org/machine-learning/decision-tree/ </li>
        <li> Schoen C, DesRoches C. Uninsured and unstably insured: the importance of continuous insurance coverage. Health Serv Res. 2000 Apr;35(1 Pt 2):187-206. PMID: 10778809; PMCID: PMC1089095.</li>
        <li> American Hospital Association. Report: The Importance of Health Coverage.  </li>
    </ul>
  
    
  </div>

  <div id="Boosting" class="tab-content">
    <h2>Xtreme Gradient Boosting (XGB)</h2>

        
    <div class="top-images">
      <img src="Website_Pic21.JPG" alt="XGB image 3">
      <img src="Website_Pic14.jpg" alt="XGB image 2">
      <img src="Website_Pic1.jpg" alt="XGB image 1">
    </div>

    
    <br>
    <h3>Overview</h3>
   
    <p> 
      By combining multiple models to improve overall performance, ensemble methods in machine learning provide a powerful alternative to a single model.  
      Ensemble techniques include boosting, bagging and stacking. For this analysis, we implement boosting, which trains models considered weak leaners 
      sequentially by focusing on misclassified points in subsequent models. As the name implies, weak learners are simple models (e.g. a decision stump 
      or a shallow decision tree). Weak learners perform only slightly better than chance. However, by combining them with boosting methods, the collective 
      result is a strong learner with greater model performance.
    </p>
    
    <p>
      Boosting models include AdaBoost, Gradient Boosting, and XGBoost (Table 13). These models iteratively reduce variability and bias in the data by 
      focusing on misclassified or hard to classify points.
    </p>

<table>
  <caption><strong>Table 13. Comparison of Boosting Methods</strong> <br>
    <em>Sources: Subha (Medium), GeeksforGeeks</em>
  </caption>
  <thead>
    <tr>
      <th> </th>
      <th>AdaBoost</th>
      <th>Gradient Boosting</th>
      <th>XGBoost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>General Approach</strong></td>
      <td>Focuses on misclassified points from previous models by increasing their weight.</td>
      <td>Builds models sequentially, with each new model correcting the residual errors of the previous model.</td>
      <td>An optimized and regularized version of Gradient Boosting that uses parallel processing and advanced regularization to prevent overfitting.</td>
    </tr>
    <tr>
      <td><strong>Base Estimators</strong></td>
      <td>Usually, decision stumps.</td>
      <td>May use deeper trees with 8–32 leaves.</td>
      <td>Uses a regularized greedy forest algorithm to build trees.</td>
    </tr>
    <tr>
      <td><strong>Handling Overfitting</strong></td>
      <td>Stumps generally prevent overfitting.</td>
      <td>Prone to overfitting if not carefully tuned.</td>
      <td>Regularization hyperparameters (L1 and L2) control complexity and help prevent overfitting.</td>
    </tr>
    <tr>
      <td><strong>Speed and Efficiency</strong></td>
      <td>Fast to train despite being a serial process.</td>
      <td>Can be slow to train due to sequential nature.</td>
      <td>Much faster and more scalable due to parallel processing and a cache-aware algorithm.</td>
    </tr>
    <tr>
      <td><strong>Use Cases</strong></td>
      <td>Simpler problems or when a quick model is needed for a small dataset.</td>
      <td>Problems where accuracy is the highest priority and computational resources are limited.</td>
      <td>Scenarios where performance, speed, and regularization are crucial.</td>
    </tr>
  </tbody>
</table>

    
    <p>
      As shown in the image below, Adaboost weights the misclassified points higher in subsequent models. This approach allows the later models to focus on hard to 
      classify records. Adaboost uses a learning rate (typically between 0.1 - 1.0) to weight the contribution of each weak learner in the overall model (weighted 
      majority vote).
    </p>
    
    <br>
    <b>Adaboost Weighting Technique</b><br>
    <img src="images/Adaboost_illustration.png" alt="Adaboost Weights" width="1200"><br><br>

    <p>
      In comparison, Gradient Boost and XGBoost minimize the residuals. As with regression, harder to classify points have larger residuals. Weak 
      learners are combined to create a strong learner (illustration below). Gradient Boost also uses a learning rate; however, it typically ranges from 0.01 to 3.0 
      and scales the contribution of each new tree to the final combined model. A smaller learning rate generally results in a better fitting model, but requires more iterations to converge.
    </p>
    
    <br>
    <b>Gradient Boosting Method (Source: CU Boulder CSCI 5612 Machine Learning for Data Science Class Notes)</b><br>
    <img src="images/Gradient_Boosting_Illustration.png" alt="Gradient Boost" width="1200"><br><br>
    
    <br>
    <h3>Data Prep</h3>
    
    <p> 
      This analysis includes both individual characteristics from NSCH and state-level data from AHR (those that do not overlap with NSCH, e.g., excluded insurance 
      coverage and poverty). The following individual-level features were kept: place to get health care (binary), age (continuous), birth sex (binary), housing instability (binary), 
      family receiving WIC (binary), family food and cash assistance (ordinal), poverty level (ordinal), count of related-family members in house (ordinal), health status
      (ordinal), continuous and adequate insurance (binary), screen time usage (ordinal), adequate sleep (binary), and highest level of education received by an adult in 
      the household (ordinal). State-level features that were kept included: percentage of the population younger than age 18, number of primary care_providers per 100,000 
      people, public health funding per capita, sum of the social support and engagement measures, and region (categorical). The target variable assesed not receiving 
      preventative care. Ordinal variables entered the model as categorical with order, binary were recoded as 0/1, and region was one-hot encoded with the first region 
      dropped. Figure 41 provides a heatmap of the features that were considered for the model.
    </p>

    <br>
    <b>Figure 41</b><br>
    <img src="images/Q10_heatmap_XGB_features.png" alt="Q10_heatmap_GGB_features" width="1200"><br><br>

    <p>
      Features, target, and weights are split into training and test sets. The split worked well for a relatively even distribution of the target variable, as shown
      in Table 14. The training and test data are disjoint because the training data are used to train the model and help it to 
      learn patterns from the data. The test data are used to evaluate the model's performance on unseen data. If the model is tested on the same data it was trained on, it 
      may appear to perform better than it actually does, which could lead to misuse of the model. Tables 15 and 16 provide the first five rows of data for the training 
      and testing data, respectively. 
    </p> 
    
    <br>
    <b>Table 14</b><br>
    <img src="images/XGB_Train_Test_Target_Split.png" alt="XGB train test split" width="400"><br><br>
    
    <br>
    <b>Table 15</b><br>
    <img src="images/XGB_Train_Data_Head.png" alt="XGB train head" width="1200"><br><br>
    
    <br>
    <b>Table 16</b><br>
    <img src="images/XGB_Test_Data_Head.png" alt="XGB test head" width="1200"><br><br>

    <p>
      Due to the data use agreement, these data are stored on a private repository. The state-level data are here: 
      <a href="https://github.com/vt-art/NSCH_AHR_Data/blob/main/NSCH_AHR_state.csv" target="_blank" rel="noopener noreferrer">
        NSCH_AHR_state.csv.  
      </a> 

      The family-level data are here:
      <a href="https://github.com/vt-art/NSCH_AHR_Data/blob/main/NSCH_fam.csv" target="_blank" rel="noopener noreferrer">
        NSCH_fam.csv.  
      </a> 

    </p>
        
    <br>
    <h3>Code</h3>
    
    <p> 
      The following Python programs contains the code for the XGBoost analyses:
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/8a_NSCH_AHR_XGB_Analysis.ipynb" target="_blank" rel="noopener noreferrer">
        8a_NSCH_AHR_XGB_Analysis.
      </a> 
      and 
      <a href="https://github.com/vt-art/NSCH-Machine-Learning-Project/blob/main/code/8b_NSCH_AHR_XGB_Analysis.ipynb" target="_blank" rel="noopener noreferrer">
        8b_NSCH_AHR_XGB_Analysis.
      </a>
      The first step of the code is to read in the state-level and individual-level data from AHR and NSCH. Next, the aforementioned features are kept and missing 
      value are replaced with the most common values. The target variable of no preventative care was constructed as 1=no preventative care, 0=preventative care 
      from the variable "PrevMed_23", which is an indicator variable for receiving preventative care. Additionally, class imbalance was addressed with scale_pos_weight
      where the imbalance weight was determined from a ratio of sample-weighted counts for negative and positive cases (i.e. spw = weighted_neg / weighted_pos). For 
      preventative care, for each positive case (i.e. no preventative care) there are 3.87 negative cases. <br>
      <br>
      
      Next, the XGBoost classifier is instanciated, fit with the above target, feature and sample weight variables, and tuned using the training data. 
      Measures of model performance are calculated, including weighted accuracy, recall, f1-score and ROC/AUC for the test set. This follows with the calculation of 
      feature importance based on gain. Additionally, we examine the first, fifth and tenth trees to assess how the data are split. This process was repeated twice.  
      First, we used the xgb.XGBClassifier() from `xgboost`. This method integrates well with sklearn; however, it is less efficient with large-survey data that requires 
      sampling weights. As such, we also implemented the XGBoost model using xgb.DMatrix(). Using DMatrix directly results in faster model-building and natural integration 
      of the sampling weights.<br> 
      <br>    
      
    </p>    
    <br>
    <h3>Results</h3> 
    
    <p> 
      Of the 54,159 children included in the NSCH, 8872 (16.38%) did not receive preventative care. We weighted and assessed these data with XGBoost. The two approaches for fitting the XGBoost model 
      resulted in almost identical results. As expected, DMatrix was much faster than xgb.XGBClassifier(). Since the 
      results were so similar, we will focus on those from DMatrix. As shown in Figure 42, the model performed okay with an accuracy was 0.67. The f1-score (0.46) and 
      recall (0.66). Although we captured 66% of the true positive cases, we missed 34%.       
    </p>
  
    <br>
    <b>Figure 42</b><br>
    <img src="images/Q10_nopcare_XGB_CM.png" alt="Q10_XGB_CM" width="1200"><br><br>

    
    <p>
      The optimal XGBoost model included the following hyperparameters:
      <ul>
        <li>"objective": "binary:logistic",    # Logistic regression on trees</li>
        <li>"eval_metric": "logloss",</li>
        <li>"tree_method": "hist",             # histogram trees- good for large weighted datasets</li>
        <li>"scale_pos_weight": float(spw),</li>
        <li>"min_child_weight": 5,</li>
        <li>"lambda":5,                        # L2 regularization</li>
        <li>"alpha":1,                         # L1 regularization</li>
        <li>"gamma":5,                         # Loss reduction needed to split</li>  
        <li>"seed": 4567</li>                         
        <li>"max_depth": 3,       </li>
        <li>"eta": 0.1,                        # using bigger eta because there are 
                                               # 14 million weighted records (54,000 
                                               # unweighted)  </li>  
        <li>"subsample": 0.9,                  # Row sampling rate - good regularization</li>
        <li>"colsample_bytree": 0.7            # feature sampling - good regularization</li>
      </ul>
      
      Based on the max-depth and regularization, the model preferred shallow, simple trees. This approach favored the large, weighted survey data used in the analysis.  <br>
      <br>
      As illustrated by Figure 43, the ROC-curve of the test data yielded an area under the curve of 0.73. This indicates that the model has a good ability to 
      distinguish between individuals needing preventative care.
    </p>
        
    <br>
    <b>Figure 43</b><br>
    <img src="images/Q10_nopcare_XGB_ROC.png" alt="Q6_insurance_DT_ROC" width="1200"><br><br>

    <p>
      The most important feature for predicting no preventative care when assessed by gain was having a usual place for care (37%) (Figure 44). Although to a lesser 
      degree, other important features included adult education (7%), the child's age (7%) and Northeastern states (5%). Figure 45 shows the directionality of the 
      effect with not having a place for care, household adults having less education, older children and not living in the Northeast were all related to not receiving 
      preventative care. 
    </p>
    
    <br>
    <b>Figure 44</b><br>
    <img src="images/Q10_nopcare_XGB_feature_importance.png" alt="Q10_XGB_feature_importance" width="1200"><br><br>

    <br>
    <b>Figure 45</b><br>
    <img src="images/Q10_XGB_predictive_features.png" alt="Q10_XGB_ROC" width="1200"><br><br>

    
      
    <br>
    <h3>Conclusions</h3>
   
    <p> 
      The XGBoost model found that not having a usual place to receive health care is the most predictive feature of not receiving preventative care. Other features, such 
      as lower education, older children and living outside of the Northeast, were also important features. This suggests that targeting those who are most likely 
      to miss visits with public health messaging and helping people find a regular place for care are viable interventions in increasing preventative care coverage.
    </p> 



    <h3>References</h3>
    
    <ul> 
        <li> Subha. Boosting — Adaboost, Gradient Boost and XGBoost. Medium. Mar 29, 2024.          
          <br>
          Available from: https://medium.com/@pingsubhak/boosting-adaboost-gradient-boost-and-xgboost-bdda87eed44e </li>
        <li> GradientBoosting vs AdaBoost vs XGBoost vs CatBoost vs LightGBM. GeeksforGeeks. Jul 23, 2025. <br>
          Available from: https://www.geeksforgeeks.org/machine-learning/gradientboosting-vs-adaboost-vs-xgboost-vs-catboost-vs-lightgbm/ </li>
    </ul>

    
  </div>

  <div id="Results" class="tab-content">
    <h2>Summary of Results</h2>

    <img src="Website_Pic8.jpg" alt="Results image"  width="1200">
    

    <p> 
      Through exploratory data analysis and machine learning, we attempted to gain insights about the health of American children from the 2023
      <a href="https://www.childhealthdata.org/learn-about-the-nsch" target="_blank">National Survey of Children's Health (NSCH)</a> 
      and 
      <a href="https://www.childhealthdata.org/learn-about-the-nsch" target="_blank">America's Health Rankings (AHR).</a> 
      We initially explored 10 questions through EDA and identified interesting patterns for questions 1, 6, 9, and 10, specifically:<br>
        <ul>
          <li>Question 1: What state-wide factors predict state-wide immunization coverage by 24-months?</li>
          <li>Question 6: What state-wide features predict state-wide insurance coverage?</li>
          <li>Question 9: Among teenagers, what features predict inadequate sleep?  </li>
          <li>Question 10: What factors contribute to children not accessing preventive care?</li>
        </ul> 
      These four questions were explored in greater detail through various unsupervised and supervised machine learning methods. Performance varied widely across models, with cluster analysis, 
      Principle Component Analysis and tree-based approaches providing the best fit for the data. Naïve Bayes performed the worst. Table 17 provides a comparison of model performance for the various 
      methods. Please refer to the individual tabs for visualizations of the findings.
    </p>

    <table>
  <caption><strong>Table 17. Model Performance</strong> <br>
  </caption>
  <thead>
    <tr>
      <th>Model</th>
      <th>Research Question</th>
      <th>Model Performance Metrics</th>
      <th>Summary of Results</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>K-Means Clustering</strong></td>
      <td>Question 1: What state-wide factors predict state-wide immunization coverage by 24-months?</td>
      <td>
          Accuracy = 0.71<br>
          Recall = 0.73<br>
          Precision = 0.70<br>
          F1-score = 0.72
      </td>
      <td>
        K-Means predicted the states on the further sides of each cluster correctly, while the area of intersection had greater misclassification. 
        There are unique similarities within states that have similar rates of insurance and preventative care coverage. States clustering together with 
        lower coverage tended to also have lower immunization coverage. Those with medium to high insurance and preventative care rates tended to also have medium to high immunization coverage. 
        These results are in-line with the visual inspection of the data which showed a positive correlation between insurance and preventative care, as well as higher immunization rates for 
        states with higher insurance and preventative care coverage. These results identify a gap for states with low coverage. Making care accessible through insurance and preventative care 
        appears to be related to higher childhood immunization rates.
      </td>
    </tr>
    <tr>
      <td><strong>Hierarchical Clustering</strong></td>
      <td>Question 1: What state-wide factors predict state-wide immunization coverage by 24-months?</td>
      <td>
          Accuracy = 0.75<br>
          Recall = 0.85<br>
          Precision = 0.71<br>
          F1-score = 0.77
      </td>
      <td>
        Performed better than K-Means. As with K-Means, the points on the further sides of each cluster were identified correctly, while the area of intersection was more problematic. Hierarchical clustering 
        also showed the same relationships as K-Means between insurance, preventative care and immunization coverage.
      </td>
    </tr>
    <tr>
      <td><strong>PCA</strong></td>
      <td>Question 1: What state-wide factors predict state-wide immunization coverage by 24-months?</td>
      <td>
          Ten features were reduced to seven, which captured 95% of the variation in the data. PC1 accounted for approximately 43% of the variation in the data, followed by PC2 with 23% of the variance.
      </td>
      <td>
        The only feature positively correlated with PC1 is the state population under age 18. We see greater variability in the loadings for PC2 with excellent or good health, a place for care, completing high school, 
        above the poverty line, engagement in the community and the population less than 18 showing positive correlation with PC2. The biplot for PC1 and PC2 shows that PC1 uniquely separates states with large numbers 
        of children under age 18 that also have lower values for primary care providers, preventative care and insurance. States in this quadrant with positive PC1 and positive PC2 include many Southern and Southwest 
        states - South Carolina, Georgia, Arkansas, Oklahoma, Texas and Nevada, as well as Indiana and New Jersey. The states in the quadrant where PC1 is negative and PC2 is positive, have higher levels of 
        health, income, completing high school, places to regularly receive care and engagement. However, this same quadrant has lower levels for features related to health care access (primary care providers, preventative 
        care and insurance). This suggests that although these states may have better education and less poverty, there may be gaps in health care coverage. Western states (Utah, Idaho, Colorado, Wyoming, Montana, Washington) 
        and mid-Western states (South Dakota, North Dakota, Minnesota, Kansas, Nebraska, Iowa, Illinois, and Ohio) primarily make up this group. Arkansas, Virginia and Maryland are also included. When both PC1 and PC2 are 
        negative, we see that states in this quadrant are higher in primary care providers, preventative care and insurance. These states are lower in population under 18 with higher completion of 
        high school and percentage above the poverty line, suggesting that what makes them unique is the high health care coverage. States in the last quadrant where PC1 is positive, but PC2 is negative have higher population 
        < 18 with some healthcare services available and weaker education and economic measures.</td>
    </tr>
    <tr>
      <td><strong>Multinomial Naïve Bayes</strong></td>
      <td>Question 9: Among teenagers, what features predict inadequate sleep?</td>
      <td>
          Accuracy = 0.68<br>
          F1-score = 0.25<br>
          Recall = 0.18<br>
          ROC-AUC = 0.56
      </td>
      <td>
        Due to extremely poor model performance with a threshold of 0.5. We completed a threshold analysis and found that 0.3 provided the best balance of accuracy, recall and f1-scores. 
        Although the model performed poorly, we assessed the log probability differences for the features. We found that the child having poorer health status and greater screen time are associated with inadequate sleep, 
        while care givers having greater education and larger family size are associated with adequate sleep.
      </td>
    </tr>
    <tr>
      <td><strong>Bernoulli Naïve Bayes</strong></td>
      <td>Question 9: Among teenagers, what features predict inadequate sleep?</td>
      <td>
          Accuracy = 0.70<br>
          F1-score = 0.23<br>
          Recall = 0.15<br>
          ROC-AUC = 0.66
      </td>
      <td>The model had high accuracy, but low F1-score and recall. As with the Multinomial Naïve Bayes, we calculated log probability differences for the features. Younger children (ages 13 and 14) and children with less 
        screen time per day (0-2 hours) were associated with having adequate sleep for their age. Conversely, older teens (ages 16 and 17), children with greater screen time per day (3 or more hours), children experiencing 
        housing instability, and children with poorer health were associated with having inadequate sleep for age. </td>
    </tr>
    <tr>
      <td><strong>Decision Tree</strong></td>
      <td>Question 6: What state-wide features predict state-wide insurance coverage?</td>
      <td>
          Accuracy = 0.75<br>
          F1-score = 0.60<br>
          Recall = 0.60<br>
          ROC-AUC = 0.71
      </td>
      <td>
        The model performed well. Per capita spending on public health topped the important features with a feature importance score of 0.5. Although to a lesser degree, other important features for predicting good 
        insurance coverage included the proportion of the population above the poverty line, use of preventative care, health status of the population and a supportive community. The optimal decision tree had a max depth of 8. 
        Public health plays an important role in the classification by splitting the root node at less than or equal to $146 per person spent on public health. For context the median value of public health spending is $123 per
        person. Branching to the left, 25 states spent $146 or less per person on public health and 23 of these were classified as not good insurance. In contrast, ten states branched to the right because they spent more than
        $146 per person on public health. Eight of these states were classified as meeting good insurance coverage.
      </td>
    </tr>
    <tr>
      <td><strong>Random Forest, and XGBoost</strong></td>
      <td>Question 9: Among teenagers, what features predict inadequate sleep?</td>
      <td>
          Accuracy = 0.57<br>
          F1-score = 0.39<br>
          Recall = 0.48<br>
          ROC-AUC = 0.58
      </td>
      <td>
        The model performed poorly at predicting inadequate sleep. Important features included not having insurance, not having a place to receive care and not having preventative care each had a feature importance score of 
        approximately 0.1.
      </td>
    </tr>    
    <tr>
      <td><strong>XGBoost</strong></td>
      <td>Question 10: What factors contribute to children not accessing preventive care?</td>
      <td>
          Accuracy = 0.67<br>
          F1-score = 0.46<br>
          Recall = 0.66<br>
          ROC-AUC = 0.73
      </td>
      <td>
        Although we captured 66% of the true positives with the model, we missed 34%. The most important feature for predicting no preventative care when assessed by gain was having a usual place for care (37%). 
        Although to a lesser degree, other important features included adult education (7%), the child's age (7%) and Northeastern states (5%). Regarding the directionality of these effects, not having a place for care, 
        household adults having less education, older children and not living in the Northeast were all related to not receiving preventative care.</td>
    </tr>  
  </tbody>
</table>

    
  </div>

  <div id="ProjectChallenges" class="tab-content">
    <h2>Project Challenges</h2>

    <div class="top-images">
      <img src="Website_Pic19.JPG" alt="NN image 3">
      <img src="Website_Pic15.jpg" alt="NN image 2">
      <img src="Website_Pic16.jpg" alt="NN image 1">
    </div>

    
    <br>
    <h3>Data Acquisition Challenges</h3>
   
    <p> 
      The US government funds several large studies on the health and well-being of children. Generally, these data are publicly available on the National Institute of Child Health and Human Development - Data and 
      Specimen Repository. However, the website has been down since May 2025 for new data requests. As such, this project relied on publicly available household survey data with location identifiers at the state-level. 
      As with many large studies, the National Survey of Child Health requires weighting the data to roll the data up to the state-level.
    </p>

    <p> 
      American Health Rankings include good documentation for accessing the data via API. However, there are many variables and determining the individual variable names to pull with the API was challenging.
    </p>
    
    <br>
    <h3>Model Challenges</h3>
   
    <p> 
      The weighted Multinomial Naïve Bayes classifier was first run with the default threshold of 0.5. The model performed poorly with zero true positives detected. As such, we conducted an analysis of the accuracy, 
      recall and f1-scores by various thresholds and determined that a threshold of 0.3 provided the best balance of these measures. From here we were able to improve the model. However, neither the multinomial nor the 
      Bernoulli Naïve Bayes models performed well.
    </p>

    <p> 
      Some of the models did not support weighting the data with sampling weights. For example, there is no support in sklearn.cluster.AgglomerativeClustering() for weights. As such, we focused on state-level analyses 
      for these models. 
    </p>

    <p> 
      The class-imbalance for our outcomes posed challenges, particularly when using the weighted-individual data. Of all the model types, XGBoost handled this the best with scale_pos_weight where the imbalance weight 
      was determined from a ratio of sample-weighted counts for negative and positive cases (i.e. spw = weighted_neg / weighted_pos). For preventative care, for each positive case (i.e. no preventative care) there are
      3.87 negative cases. We were able to incorporate this with the sampling weights for the individual subjects.
    </p> 

    
  </div>

  <div id="" class="tab-content"> 
    
    <h1>Conclusions</h1>  
    
    <div class="top-images">
      <img src="Website_Pic11.JPG" alt="Conclusion image 3">
      <img src="Website_Pic9.jpg" alt="Conclusion image 2">
      <img src="Website_Pic18.JPG" alt="Conclusion image 1">
    </div>
        
    <h3>Summary of findings</h3>
    
    <p>    
        This research found several important findings across our main outcomes of rates of full vaccination by 24 months, sufficient sleep among teenagers, 
        adequate insurance coverage, and uptake of preventative care. We found that preventative care and insurance coverage are good predictors of immunization coverage. 
        K-Means and hierarchical clustering illustrated that states that have similar rates of insurance and preventative care coverage cluster together. Those with 
        lower coverage tended to also have lower immunization rates. Those with medium to high insurance and preventative care rates also clustered together. This group 
        tended to also have medium to high immunization coverage. These results show the interrelatedness of preventative care with insurance and immunizations. 
        They identify that a gap in coverage for insurance and preventative care corresponds to a gap in childhood immunization rates. This interdependency suggests that 
        improving one of these measures may positively influence the others. PCA analysis supported these findings and showed that states with higher populations <18, 
        fewer primary care providers, less preventative care and reduced insurance coverage may require additional support to increase immunization coverage.
    </p>

    <p>
        Median vaccine coverage was 67.7% across the states. If we considered < 67.5% as low coverage and 67.5% or greater as medium to high coverage, EDA showed that the percentage of children receiving at 
        least one preventative care visit is slightly higher in the medium or high group. Specifically, in the low immunization group, a median of 79.4% of children and for the medium or high group, a median of 80.9% of 
        children received a preventative care visit. The decision tree with the state-level outcome of good insurance found that per capita spending on public health of at least $147 per person delineated the data fairly 
        well into states with and without good insurance coverage. This has important implications for states hoping to bolster insurance coverage for their residents. Since the 
        median public health spending is $123, on average states would only need to increase their spending by approximately $24 per person in order to reach this threshold. 
        Such an investment could provide residents with greater access to health coverage. According to the American Hospital Association, "studies confirm that coverage improves 
        access to care; supports positive health outcomes, including an individual’s sense of their own health and well-being; incentivizes appropriate use of health care resources; 
        and reduces financial strain on individuals, families and communities.
    </p>

    <p>
        The American Academy of Sleep Medicine recommends that to promote optimal health, teens should regularly sleep eight to 10 hours per 24-hour period (Ref: Paruthi). 
        EDA found that limiting screen time appears to play a role for adequate hours of sleep for teenagers. Once the average hours of screen time exceed 1 hour per day, the weighted proportion of teens experiencing 
        inadequate sleep nearly doubles from 17% for 1 hour to 33% for 4 or more hours. For the detailed sleep analysis, we employed a Bernoulli Naïve Bayes. Influential features 
        for inadequate sleep included: older teens, greater screentime (3+ hrs/day), housing instability and children in poorer health. Helping these groups obtain enough sleep could improve their 
        overall physical and mental health.
    </p>
  
    <p>
        The percentage of children receiving at least one preventative care visit ranged from 69.8% to 89.3%. EDA identified that poverty and moving were associated with not receiving preventative care. 
        States reported over 10% of households living below the federal poverty level (median(P25, P75) = 12.2(11.05,13.65)). As the percentage of households below the federal poverty level increases 
        (i.e. more people living in poverty), the percentage of children receiving preventative care decreases. Additionally, children experiencing housing instability or living three or more places in 
        the last year received a preventative care visit 69% of the time. Conversely, 80% of children who did not move more than once experienced a preventative care visit. The XGBoost model found that 
        not having a usual place to receive health care is the most predictive feature of not receiving preventative care. Other features, such 
        as lower education, older children and living outside of the Northeast, were also important features. This suggests that targeting those who are most likely to miss 
        visits with public health messaging and helping people find a regular place for care are viable interventions in increasing preventative care coverage.  
    </p>
    
    
  </div>


  <div id="References" class="tab-content">
    
    <h1>References</h1>

    <img src="Website_Pic5.jpg" alt="Results image"  width="1200">
    
<ol class="ref-list">
  <li>WHO–UNICEF–Lancet Commission, 2020.</li>

  <li>
    National Academies of Sciences, Engineering, and Medicine. 2024. 
    <i>Launching Lifelong Health by Improving Health Care for Children, Youth, and Families.</i> 
    Washington, DC: The National Academies Press. 
    <a href="https://doi.org/10.17226/27835" target="_blank">https://doi.org/10.17226/27835</a>
  </li>

  <li>
    Mandela, N. <i>Address by Nelson Mandela at Vaccine Conference.</i> South Africa 2002. 
    <a href="http://www.mandela.gov.za/mandela_speeches/2002/0204_vaccine.htm" target="_blank">
      http://www.mandela.gov.za/mandela_speeches/2002/0204_vaccine.htm
    </a>
  </li>

  <li>
    National Academies of Sciences, Engineering, and Medicine… 2024 Dec 30. 
    <i>Child Health and Health Care: Uniqueness, Societal Importance, and Vision for the Future.</i>
    Available from: 
    <a href="https://www.ncbi.nlm.nih.gov/books/NBK610738/" target="_blank">
      https://www.ncbi.nlm.nih.gov/books/NBK610738/
    </a>
  </li>

  <li>
    United Nations International Children’s Emergency Fund (UNICEF). Report card no. 6: 
    <i>Child poverty in rich countries 2005.</i> UNICEF Innocenti Research Centre; 2005.
    <a href="https://www.unicef-irc.org/publications/pdf/repcard6e.pdf" target="_blank">
      https://www.unicef-irc.org/publications/pdf/repcard6e.pdf
    </a>
  </li>

  <li>
    Davis, Alex. <i>A Guide to Clustering Algorithms.</i> Towards Data Science. Sep 6, 2024.
  </li>

  <li>
    Andreoni, Riccardo. <i>Dimensionality Reduction Made Simple.</i> Towards Data Science. Feb 7, 2024.
  </li>

  <li>
    Sena, Marcus. <i>Principal Component Analysis Made Easy.</i> Towards Data Science. Jun 8, 2024.
  </li>

  <li>
    <i>Feature Selection Techniques in Machine Learning.</i> GeeksforGeeks. Aug 30, 2025.
  </li>

  <li>
    <i>What is Feature Extraction?</i> GeeksforGeeks. Aug 30, 2025.
  </li>

  <li>
    Mueller, Vincent. <i>Eigenvalues and eigenvectors in PCA.</i> Sep 18, 2021.
  </li>

  <li>
    Baladram, S. <i>Bernoulli Naive Bayes, Explained.</i> Towards Data Science. Aug 2024.  
    <a href="https://towardsdatascience.com/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6/" target="_blank">
      https://towardsdatascience.com/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6/
    </a>
  </li>

  <li>
    Yıldırım, S. <i>Naive Bayes Classifier – Explained.</i> Medium (TDS Archive). Feb 2020.  
    <a href="https://medium.com/data-science/naive-bayes-classifier-explained-50f9723571ed" target="_blank">
      https://medium.com/data-science/naive-bayes-classifier-explained-50f9723571ed
    </a>
  </li>

  <li>
    Mocquin, Y. <i>Multinomial Naive Bayes Classifier.</i> Towards Data Science. Mar 2024.  
    <a href="https://towardsdatascience.com/multinomial-naive-bayes-classifier-c861311caff9/" target="_blank">
      https://towardsdatascience.com/multinomial-naive-bayes-classifier-c861311caff9/
    </a>
  </li>

  <li>
    Paruthi, S., Brooks L., D'Ambrosio C., et al. <i>Recommended Amount of Sleep for Pediatric Populations.</i>  
    Journal of Clinical Sleep Medicine (2016).  
    <a href="https://doi.org/10.5664/jcsm.5866" target="_blank">https://doi.org/10.5664/jcsm.5866</a>
  </li>

  <li>
    Dash, S. <i>Decision Trees Explained – Entropy, Information Gain, Gini Index, CCP Pruning.</i>  
    Towards Data Science. Nov 2022.  
    <a href="https://towardsdatascience.com/decision-trees-explained-entropy-information-gain-gini-index-ccp-pruning-4d78070db36c/" target="_blank">
      https://towardsdatascience.com/decision-trees-explained-entropy-information-gain-gini-index-ccp-pruning-4d78070db36c/
    </a>
  </li>

  <li>
    <i>Decision Trees.</i> Geeks for Geeks. June 2025.  
    <a href="https://www.geeksforgeeks.org/machine-learning/decision-tree/" target="_blank">
      https://www.geeksforgeeks.org/machine-learning/decision-tree/
    </a>
  </li>

  <li>
    Schoen C, DesRoches C. <i>Uninsured and unstably insured: the importance of continuous insurance coverage.</i>  
    Health Serv Res. 2000 Apr;35(1 Pt 2):187–206. PMID: 10778809; PMCID: PMC1089095.
  </li>

  <li>
    American Hospital Association. <i>Report: The Importance of Health Coverage.</i>
  </li>

  <li> 
    Subha. Boosting — Adaboost, Gradient Boost and XGBoost. Medium. Mar 29, 2024.          
    Available from: https://medium.com/@pingsubhak/boosting-adaboost-gradient-boost-and-xgboost-bdda87eed44e </i>
  </li>
    
  <li> 
    GradientBoosting vs AdaBoost vs XGBoost vs CatBoost vs LightGBM. GeeksforGeeks. Jul 23, 2025. 
    Available from: https://www.geeksforgeeks.org/machine-learning/gradientboosting-vs-adaboost-vs-xgboost-vs-catboost-vs-lightgbm/ </i>
  </li>
  
</ol>
    
  </div>

  <div id="About_Me" class="tab-content">
    
    <h1>About Me</h1>
  
  <p>
    I’m a biostatistician and data scientist with over 20 years of experience applying statistical methods,
    data management, and programming to address complex challenges in public health, healthcare, and social
    science research. I hold master's degrees in Maternal and Child Health and Biostatistics from the
    University of North Carolina Chapel Hill (2003).
  </p>

  <p>
    Currently, I’m expanding my skill set as a full-time master’s student in the Data Science program at the
    University of Colorado Boulder (expected graduation May 2026).
  </p>

  <p>
    Alongside my studies, I work part-time as a research biostatistician at RTI International, where I’ve spent most
    of my career.
  </p>

  <p>
    Above all, I am mission-focused and purpose-driven. My passion lies in using data to advance knowledge, influence
    policy, and create lasting, positive change for communities and families.
  </p>

  <hr>

  <h3>Coursework</h3>
  <p>My academic coursework at CU Boulder includes:</p>
  <ul>
    <li>data structures and algorithms</li>
    <li>frequentist and Bayesian statistics</li>
    <li>data mining</li>
    <li>machine learning</li>
    <li>applied deep learning</li>
  </ul>

  <p>
    In addition to being proficient in SAS, I’m building fluency in Python and R and continually learning
    modern data science tools and frameworks.
  </p>

  <hr>

  <h3>Work Experience</h3>

  <p>I’ve led statistical teams and contributed to more than a dozen large-scale maternal and child health studies, including:</p>
  <ul>
    <li>randomized controlled trials</li>
    <li>observational cohorts</li>
    <li>evaluation projects</li>
  </ul>

  <p>My work spans the full research lifecycle:</p>
  <ul>
    <li>protocol development and study design</li>
    <li>advanced modeling</li>
    <li>data analysis</li>
    <li>publication</li>
  </ul>

  <p>
    I've co-authored more than 50 peer-reviewed publications and actively support capacity building by mentoring junior
    analysts and collaborating with global partners across the U.S., South Asia, Africa, and Central America.
  </p>

  <hr>

  <h3>Selected Project Experience</h3>

  <ul>
    <li>
      <a href="https://numom2b.org/" target="_blank">
        NHLBI nuMoM2b Heart Health Study 2
      </a>
      – Domestic network of observational and lab studies about heart health, particularly among those who experienced
      an adverse pregnancy outcome (2020 to date)
    </li>

    <li>
      <a href="https://globalnetwork.azurewebsites.net/" target="_blank">
        NICHD Global Network for Women’s and Children’s Health Research
      </a>
      – International network of RCTs, registry, lab, and observational studies across 7 clinical sites, focusing on
      impactful interventions promoting maternal and child health in low-resource areas (2004 to date)
    </li>

    <li>
      <a href="https://www.isrctn.com/ISRCTN44033252" target="_blank">
        WHO and BMGF Possible Severe Bacterial Infection (PSBI) Trial
      </a>
      – International RCT in 7 countries evaluating care for infants with PSBI (2020 to 2025)
    </li>

    <li>
      <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3665402/" target="_blank">
        NICHD Stillbirth Collaborative Research Network
      </a>
      – Domestic case-control, vital record, and lab analysis study of stillbirth in the US (2003 to 2017)
    </li>

    <li>
      <a href="https://pubmed.ncbi.nlm.nih.gov/17413262/" target="_blank">
        NIMH HIV/Sexually Transmitted Disease Prevention Trial (C-POL)
      </a>
      – International HIV-prevention evaluation study in 5 countries (2006 to 2009)
    </li>

    <li>
      <a href="https://www.measureevaluation.org/resources/publications/ms-05-13.html" target="_blank">
        USAID Priorities for Local AIDS Control Efforts
      </a>
      – International HIV-prevention evaluation study (2002 to 2003)
    </li>

    <li>
      <a href="https://iris.who.int/handle/10665/269468" target="_blank">
        USAID Evaluation of Tanzanian Information Systems
      </a>
      – International program evaluation of data collection systems in Tanzania (2002 to 2003)
    </li>
  </ul>

  <hr>

  <h3>Publications</h3>

  <p><strong>Select Publications</strong></p>

  <ul>
    <li>
      Patterson JK, Thorsten VR, Eggleston B, et al. (2023) Building a predictive model of low birth weight in
      low- and middle-income countries: a prospective cohort study.
      <em>BMC Pregnancy Childbirth</em>. 22;23(1):600.
      doi: 10.1186/s12884-023-05866-1.
    </li>

    <li>
      Shankar, K., Hwang, K., Westcott, J.L., et al. (2023). Associations between ambient temperature and pregnancy outcomes
      from three south Asian sites of the Global Network Maternal Newborn Health Registry: A retrospective cohort study.
      <em>BJOG: An International Journal of Obstetrics and Gynaecology</em>.
      http://doi.org/10.1111/1471-0528.17616.
    </li>

    <li>
      Althabe, F., Belizan, J. M., McClure, E. M., et al. (2015). A population-based, multifaceted strategy to implement
      antenatal corticosteroid treatment versus standard care for the reduction of neonatal mortality due to preterm birth
      in low-income and middle-income countries: The ACT cluster-randomised trial.
      <em>Lancet</em>, 385(9968), 629–639.
      https://doi.org/10.1016/S0140-6736(14)61651-2.
    </li>

    <li>
      Reddy, U. M., Page, G., Saade, G. R., et al. (2012). Karyotype versus microarray testing for genetic abnormalities
      after stillbirth. <em>New England Journal of Medicine</em>, 367(23), 2185–2193.
      https://doi.org/10.1056/NEJMoa1201569.
    </li>
  </ul>

  <p><strong>Full List of Publications</strong><br>
    <a href="https://www.ncbi.nlm.nih.gov/myncbi/vanessa.thorsten.1/bibliography/public/" target="_blank">
      https://www.ncbi.nlm.nih.gov/myncbi/vanessa.thorsten.1/bibliography/public/
    </a>
  </p>

  <hr>

  <h3>Contact Information</h3>
  <ul>
    <li>GitHub: <a href="https://github.com/vt-art" target="_blank">@vt-art</a></li>
    <li>LinkedIn: <a href="https://www.linkedin.com/in/vanessa-thorsten-8500a64/" target="_blank">Vanessa Thorsten</a></li>
    <li>Email: <a href="mailto:vanessa.thorsten@proton.me">vanessa.thorsten@proton.me</a></li>
  </ul>

</div>



  
  <!-- JavaScript for Tab Switching -->
  <script>
    function openTab(event, tabId) {
      // Hide all tab content
      const contents = document.querySelectorAll('.tab-content');
      contents.forEach(c => c.classList.remove('active'));

      // Remove active class from all buttons
      const tabs = document.querySelectorAll('.tab-link');
      tabs.forEach(t => t.classList.remove('active'));

      // Show the selected tab and mark the button as active
      document.getElementById(tabId).classList.add('active');
      event.currentTarget.classList.add('active');
    }
  </script>

</body>
</html>
